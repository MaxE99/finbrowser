2022-05-14 10:45:20,900 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 10:45:20,916 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] received
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 2022-05-14 02:53:09+00:00
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 20220514-025309
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 2022-05-14 02:52:36+00:00
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 20220514-025236
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 2022-05-14 02:52:08+00:00
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 20220514-025208
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 2022-05-14 02:48:38+00:00
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 20220514-024838
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - 2022-05-14 02:47:50+00:00
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - 20220514-024750
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 2022-05-13 23:47:38+00:00
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 20220513-234738
2022-05-14 10:45:22,161 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 2022-05-13 21:06:15+00:00
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 20220513-210615
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 2022-05-13 20:16:48+00:00
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 20220513-201648
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - 2022-05-13 18:01:09+00:00
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - 20220513-180109
2022-05-14 10:45:22,186 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 2022-05-13 16:31:18+00:00
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 20220513-163118
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 2022-05-13 16:20:49+00:00
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 20220513-162049
2022-05-14 10:45:22,218 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] succeeded in 1.3010347979979997s: None
2022-05-14 11:00:20,904 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:00:20,907 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] received
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:00:21,743 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:15:20,912 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:15:20,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] received
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:15:21,742 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:15:21,745 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:30:20,919 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:30:20,921 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] received
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:30:21,772 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:44:25,559 - celery.beat - INFO - beat: Starting...
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Exception ignored in atexit callback
2022-05-14 11:44:29,751 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,751 - celery.redirected - WARNING - <function _exit_function at 0x7f45a0622d40>
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Traceback (most recent call last):
2022-05-14 11:44:29,751 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 334, in _exit_function
2022-05-14 11:44:29,754 - celery.redirected - WARNING -     
2022-05-14 11:44:29,754 - celery.redirected - WARNING - _run_finalizers(0)
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
2022-05-14 11:44:29,755 - celery.redirected - WARNING -     
2022-05-14 11:44:29,755 - celery.redirected - WARNING - finalizer()
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
2022-05-14 11:44:29,756 - celery.redirected - WARNING -     
2022-05-14 11:44:29,756 - celery.redirected - WARNING - res = self._callback(*self._args, **self._kwargs)
2022-05-14 11:44:29,756 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/billiard/pool.py", line 1662, in _terminate_pool
2022-05-14 11:44:29,757 - celery.redirected - WARNING -     
2022-05-14 11:44:29,758 - celery.redirected - WARNING - cls._help_stuff_finish(*help_stuff_finish_args)
2022-05-14 11:44:29,758 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 1341, in _help_stuff_finish
2022-05-14 11:44:29,759 - celery.redirected - WARNING -     
2022-05-14 11:44:29,759 - celery.redirected - WARNING - readable, _, again = _select(inqR, timeout=0.5)
2022-05-14 11:44:29,759 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 165, in _select
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,760 - celery.redirected - WARNING - return poll(readers, writers, err, timeout)
2022-05-14 11:44:29,760 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 121, in _select_imp
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,761 - celery.redirected - WARNING - events = poller.poll(timeout)
2022-05-14 11:44:29,761 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/apps/worker.py", line 299, in _handle_request
2022-05-14 11:44:29,761 - celery.redirected - WARNING -     
2022-05-14 11:44:29,762 - celery.redirected - WARNING - raise exc(exitcode)
2022-05-14 11:44:29,762 - celery.redirected - WARNING - celery.exceptions
2022-05-14 11:44:29,762 - celery.redirected - WARNING - .
2022-05-14 11:44:29,762 - celery.redirected - WARNING - WorkerTerminate
2022-05-14 11:44:29,762 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,763 - celery.redirected - WARNING - 1
2022-05-14 11:44:31,843 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:32,393 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 11:44:32,396 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 11:44:32,401 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:33,413 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 11:44:33,438 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 11:44:33,438 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 11:44:35,042 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:15:20,941 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:15:20,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] received
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 2022-05-14 12:15:10+00:00
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'float'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 1652530510.0
2022-05-14 12:15:21,757 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] raised unexpected: TypeError('expected string or bytes-like object')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    cache.set('last_id', last_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1367, in to_python
    parsed = parse_datetime(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/utils/dateparse.py", line 107, in parse_datetime
    match = datetime_re.match(value)
TypeError: expected string or bytes-like object
2022-05-14 12:17:57,522 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:58,032 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:17:58,038 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:17:58,044 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:59,055 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:17:59,075 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:17:59,075 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:18:16,642 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:18:26,059 - celery.beat - INFO - beat: Starting...
2022-05-14 12:18:26,144 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:18:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] received
2022-05-14 12:18:26,962 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,966 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,975 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,981 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,987 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,993 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,999 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,005 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,011 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,020 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,026 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,032 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,038 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,044 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,050 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,052 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,055 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,086 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,094 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,125 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,141 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,193 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,251 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] succeeded in 1.0985599829982675s: None
2022-05-14 12:33:26,149 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:33:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] received
2022-05-14 12:33:27,054 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,067 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,069 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,095 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,104 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,107 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,134 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,183 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,208 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,214 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,269 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] succeeded in 1.1157525369999348s: None
2022-05-14 12:37:40,583 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:41,124 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:37:41,127 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:37:41,131 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:42,140 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:37:42,153 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:37:42,153 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:37:55,496 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:38:01,602 - celery.beat - INFO - beat: Starting...
2022-05-14 12:48:26,166 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:48:26,181 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] received
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - 2022-05-14 12:48:07+00:00
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 12:48:27,082 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] raised unexpected: ValidationError(['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 12:57:17,676 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:18,242 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:57:18,245 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:57:18,249 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:19,259 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:57:19,269 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:57:19,269 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:57:28,245 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:57:29,701 - celery.beat - INFO - beat: Starting...
2022-05-14 13:03:26,167 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:03:26,184 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] received
2022-05-14 13:03:27,079 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,090 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,114 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,155 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,180 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,203 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,225 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,232 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,234 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,257 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] succeeded in 1.071642716997303s: None
2022-05-14 13:18:26,172 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:18:26,175 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] received
2022-05-14 13:18:27,063 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,070 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,072 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,084 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,085 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,087 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,105 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,124 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,150 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] succeeded in 0.9730412339995382s: None
2022-05-15 06:03:29,186 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:29,708 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-15 06:03:29,712 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-15 06:03:29,726 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:30,739 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-15 06:03:30,759 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-15 06:03:30,760 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-15 06:03:59,089 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-15 06:04:19,529 - celery.beat - INFO - beat: Starting...
2022-05-15 06:04:19,604 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:04:19,611 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] received
2022-05-15 06:04:21,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] succeeded in 1.4147976009999752s: None
2022-05-15 06:19:19,609 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:19:19,612 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] received
2022-05-15 06:19:20,640 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] succeeded in 1.026817458000096s: None
2022-05-15 06:34:19,613 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:34:19,615 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] received
2022-05-15 06:34:21,305 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] succeeded in 1.6879922109997096s: None
2022-05-15 06:49:19,621 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:49:19,624 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] received
2022-05-15 06:49:20,681 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] succeeded in 1.0558503859997472s: None
2022-05-15 07:04:19,629 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:04:19,631 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] received
2022-05-15 07:04:20,602 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] succeeded in 0.9688271340000938s: None
2022-05-15 07:19:19,636 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:19:19,639 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] received
2022-05-15 07:19:20,583 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] succeeded in 0.9425648280002861s: None
2022-05-15 07:34:19,645 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:34:19,647 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] received
2022-05-15 07:34:20,651 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] succeeded in 1.0023042969996823s: None
2022-05-15 07:49:19,650 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:49:19,652 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] received
2022-05-15 07:49:25,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] succeeded in 6.01083675100017s: None
2022-05-15 08:04:19,651 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:04:19,653 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] received
2022-05-15 08:04:20,689 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] succeeded in 1.0345966639997641s: None
2022-05-15 08:19:19,654 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:19:19,656 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] received
2022-05-15 08:19:20,596 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] succeeded in 0.9384977319987229s: None
2022-05-15 08:34:19,660 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:34:19,663 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] received
2022-05-15 08:34:20,747 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] succeeded in 1.0831241819996649s: None
2022-05-15 08:49:19,668 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:49:19,671 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] received
2022-05-15 08:49:20,734 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] succeeded in 1.0619436870001664s: None
2022-05-15 09:04:19,677 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:04:19,679 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] received
2022-05-15 09:04:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] succeeded in 1.0476529040006426s: None
2022-05-15 09:19:19,684 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:19:19,686 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] received
2022-05-15 09:19:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] succeeded in 1.0407590319991868s: None
2022-05-15 09:34:19,689 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:34:19,690 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] received
2022-05-15 09:34:20,793 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] succeeded in 1.1009754080005223s: None
2022-05-15 09:49:19,698 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:49:19,700 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] received
2022-05-15 09:49:20,824 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] succeeded in 1.1221691869995993s: None
2022-05-15 10:04:19,707 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:04:19,709 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] received
2022-05-15 10:04:20,620 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] succeeded in 0.9095417999997153s: None
2022-05-15 10:19:19,714 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:19:19,715 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] received
2022-05-15 10:19:20,752 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] succeeded in 1.0352385839996714s: None
2022-05-15 10:34:19,718 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:34:19,721 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] received
2022-05-15 10:34:32,181 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] succeeded in 12.45846082800199s: None
2022-05-15 10:49:19,725 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:49:19,729 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] received
2022-05-15 10:49:20,735 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] succeeded in 1.004684849998739s: None
2022-05-15 11:04:19,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:04:19,736 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] received
2022-05-15 11:04:20,698 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] succeeded in 0.9611234969997895s: None
2022-05-15 11:19:19,741 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:19:19,744 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] received
2022-05-15 11:19:20,751 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] succeeded in 1.005611074000626s: None
2022-05-15 11:34:19,743 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:34:19,745 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] received
2022-05-15 11:34:20,827 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] succeeded in 1.079889598000591s: None
2022-05-15 11:49:19,751 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:49:19,754 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] received
2022-05-15 11:49:20,799 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] succeeded in 1.0442504599996028s: None
2022-05-15 12:04:19,760 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:04:19,762 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] received
2022-05-15 12:04:20,807 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] succeeded in 1.0433865410013823s: None
2022-05-15 12:19:19,768 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:19:19,771 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] received
2022-05-15 12:19:20,846 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] succeeded in 1.0730322370000067s: None
2022-05-15 12:34:19,776 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:34:19,779 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] received
2022-05-15 12:34:20,870 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] succeeded in 1.0889358870008436s: None
2022-05-15 12:49:19,784 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:49:19,786 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] received
2022-05-15 12:49:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] succeeded in 1.0519879430030414s: None
2022-05-15 13:04:19,791 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:04:19,793 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] received
2022-05-15 13:04:20,856 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] succeeded in 1.0612804999982473s: None
2022-05-15 13:19:19,798 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:19:19,800 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] received
2022-05-15 13:19:20,847 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] succeeded in 1.0460207639989676s: None
2022-05-15 13:34:19,804 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:34:19,806 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] received
2022-05-15 13:34:20,905 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] succeeded in 1.09683028499785s: None
2022-05-15 13:49:19,813 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:49:19,816 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] received
2022-05-15 13:49:20,842 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] succeeded in 1.0248260299995309s: None
2022-05-15 14:04:19,822 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:04:19,825 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] received
2022-05-15 14:04:20,918 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] succeeded in 1.092042811000283s: None
2022-05-15 14:19:19,830 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:19:19,832 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] received
2022-05-15 14:19:20,930 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] succeeded in 1.096971050999855s: None
2022-05-15 14:34:19,838 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:34:19,841 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] received
2022-05-15 14:34:20,946 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] succeeded in 1.1038280469983874s: None
2022-05-15 14:49:19,848 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:49:19,852 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] received
2022-05-15 14:49:20,955 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] succeeded in 1.1017984110003454s: None
2022-05-15 15:04:19,849 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:04:19,850 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] received
2022-05-15 15:04:20,844 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] succeeded in 0.9928378679978778s: None
2022-05-15 15:19:19,857 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:19:19,859 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] received
2022-05-15 15:19:21,020 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] succeeded in 1.1604612469964195s: None
2022-05-15 15:34:19,865 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:34:19,869 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] received
2022-05-15 15:34:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] succeeded in 1.1178659559955122s: None
2022-05-15 15:49:19,873 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:49:19,876 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] received
2022-05-15 15:49:21,089 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] succeeded in 1.2116717239987338s: None
2022-05-15 16:04:19,881 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:04:19,884 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] received
2022-05-15 16:04:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] succeeded in 0.955031568002596s: None
2022-05-15 16:19:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:19:19,891 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] received
2022-05-15 16:19:20,974 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] succeeded in 1.0816527050046716s: None
2022-05-15 16:34:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:34:19,890 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] received
2022-05-15 16:34:20,976 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] succeeded in 1.084029563004151s: None
2022-05-15 16:49:19,897 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:49:19,901 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] received
2022-05-15 16:49:20,863 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] succeeded in 0.9598387660007575s: None
2022-05-15 17:04:19,907 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:04:19,909 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] received
2022-05-15 17:04:20,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] succeeded in 1.0509080920019187s: None
2022-05-15 17:19:19,913 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:19:19,915 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] received
2022-05-15 17:19:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] succeeded in 1.072206360004202s: None
2022-05-16 06:31:28,696 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:29,188 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 06:31:29,192 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 06:31:29,198 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:30,211 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 06:31:30,234 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 06:31:30,234 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 06:31:52,646 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 06:32:03,510 - celery.beat - INFO - beat: Starting...
2022-05-16 06:32:03,583 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:32:03,591 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] received
2022-05-16 06:32:04,722 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] succeeded in 1.1300137550001637s: None
2022-05-16 06:47:03,590 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:47:03,594 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] received
2022-05-16 06:47:04,597 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] succeeded in 1.0018781310000122s: None
2022-05-16 07:02:03,594 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:02:03,595 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] received
2022-05-16 07:02:04,390 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] succeeded in 0.7929100269998344s: None
2022-05-16 07:17:03,602 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:17:03,605 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] received
2022-05-16 07:17:04,589 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] succeeded in 0.9824386569998751s: None
2022-05-16 07:32:03,610 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:32:03,613 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] received
2022-05-16 07:32:04,675 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] succeeded in 1.060695518999637s: None
2022-05-16 07:47:03,618 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:47:03,621 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] received
2022-05-16 07:47:04,455 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] succeeded in 0.8333607330005179s: None
2022-05-16 08:02:03,627 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:02:03,629 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] received
2022-05-16 08:02:04,563 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] succeeded in 0.9320107300000018s: None
2022-05-16 08:17:03,630 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:17:03,632 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] received
2022-05-16 08:17:04,611 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] succeeded in 0.9778952010001376s: None
2022-05-16 08:32:03,634 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:32:03,635 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] received
2022-05-16 08:32:04,770 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] succeeded in 1.1333998769987375s: None
2022-05-16 08:39:40,192 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:40,697 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 08:39:40,700 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 08:39:40,705 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:41,716 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 08:39:41,735 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 08:39:41,735 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 08:39:54,573 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 08:39:59,197 - celery.beat - INFO - beat: Starting...
2022-05-16 08:47:03,643 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:47:03,660 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] received
2022-05-16 08:47:04,618 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] succeeded in 0.9568373130005057s: None
2022-05-16 09:02:03,647 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:02:03,650 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] received
2022-05-16 09:02:04,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] succeeded in 1.0120177360004163s: None
2022-05-16 09:17:03,656 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:17:03,658 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] received
2022-05-16 09:17:04,576 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] succeeded in 0.916462129998763s: None
2022-05-16 11:18:07,814 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:08,322 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 11:18:08,326 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 11:18:08,331 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:09,342 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 11:18:09,365 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 11:18:09,365 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 11:18:27,255 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 11:18:33,866 - celery.beat - INFO - beat: Starting...
2022-05-16 11:18:33,937 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:18:33,943 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] received
2022-05-16 11:18:34,988 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] succeeded in 1.043751881999924s: None
2022-05-16 11:33:33,944 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:33:33,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] received
2022-05-16 11:33:34,928 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] succeeded in 0.9800666160008404s: None
2022-05-16 11:48:33,952 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:48:33,955 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] received
2022-05-16 11:48:34,967 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] succeeded in 1.0106207190001442s: None
2022-05-16 12:03:33,961 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:03:33,963 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] received
2022-05-16 12:03:34,914 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] succeeded in 0.9488894599999185s: None
2022-05-16 12:18:33,969 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:18:33,972 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] received
2022-05-16 12:18:35,003 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] succeeded in 1.0293517479985894s: None
2022-05-16 12:33:33,978 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:33:33,980 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] received
2022-05-16 12:33:35,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] succeeded in 1.0450792589981575s: None
2022-05-16 12:48:33,985 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:48:33,987 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] received
2022-05-16 12:48:34,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] succeeded in 0.8715320560004329s: None
2022-05-16 13:03:33,987 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:03:33,990 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] received
2022-05-16 13:03:35,244 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] succeeded in 1.2528620049997699s: None
2022-05-16 13:18:33,996 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:18:33,999 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] received
2022-05-16 13:18:35,009 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] succeeded in 1.0087815840015537s: None
2022-05-16 13:33:34,002 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:33:34,005 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] received
2022-05-16 13:33:35,025 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] succeeded in 1.0186987089982722s: None
2022-05-16 13:48:34,010 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:48:34,012 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] received
2022-05-16 13:48:35,014 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] succeeded in 0.9997603140000138s: None
2022-05-16 14:03:34,012 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:03:34,015 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] received
2022-05-16 14:03:34,956 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] succeeded in 0.9401612419969751s: None
2022-05-16 14:18:34,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:18:34,018 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] received
2022-05-16 14:18:35,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] succeeded in 1.127597689999675s: None
2022-05-16 14:33:34,025 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:33:34,028 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] received
2022-05-16 14:33:35,054 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] succeeded in 1.0247761360005825s: None
2022-05-16 14:48:34,034 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:48:34,037 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] received
2022-05-16 14:48:35,024 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] succeeded in 0.9848959180017118s: None
2022-05-16 15:03:34,044 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:03:34,046 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] received
2022-05-16 15:03:35,119 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] succeeded in 1.0713062119975802s: None
2022-05-16 15:18:34,052 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:18:34,055 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] received
2022-05-16 15:18:35,032 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] succeeded in 0.9751865090001957s: None
2022-05-16 15:33:34,059 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:33:34,061 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] received
2022-05-16 15:33:35,134 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] succeeded in 1.0715108379954472s: None
2022-05-16 15:48:34,066 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:48:34,069 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] received
2022-05-16 15:48:35,038 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] succeeded in 0.9677790190035012s: None
2022-05-16 16:03:34,073 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:03:34,076 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] received
2022-05-16 16:03:35,171 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] succeeded in 1.0940112339958432s: None
2022-05-16 16:18:34,082 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:18:34,084 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] received
2022-05-16 16:18:34,997 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] succeeded in 0.9118851110033575s: None
2022-05-16 16:33:34,090 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:33:34,093 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] received
2022-05-16 16:33:35,199 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] succeeded in 1.1039589670035639s: None
2022-05-16 16:48:34,098 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:48:34,100 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] received
2022-05-16 16:48:35,190 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] succeeded in 1.088534027003334s: None
2022-05-16 17:03:34,106 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 17:03:34,108 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] received
2022-05-16 17:03:35,117 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] succeeded in 1.007733956001175s: None
2022-05-17 06:31:51,531 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 06:31:52,049 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 06:31:52,054 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 06:31:52,060 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 06:31:53,071 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 06:31:53,091 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 06:31:53,091 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 06:32:15,085 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 06:32:21,900 - celery.beat - INFO - beat: Starting...
2022-05-17 06:32:21,975 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 06:32:21,983 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ee309754-fdd9-47ba-9b2a-e4b928175356] received
2022-05-17 06:32:28,455 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ee309754-fdd9-47ba-9b2a-e4b928175356] succeeded in 6.470285474000093s: None
2022-05-17 06:47:21,982 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 06:47:21,984 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1d28fc00-5322-4e65-b4db-a687cbda811d] received
2022-05-17 06:47:23,077 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1d28fc00-5322-4e65-b4db-a687cbda811d] succeeded in 1.0906010009998681s: None
2022-05-17 07:02:21,991 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:02:21,993 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6a16bd68-44e0-4371-9f16-cf9d43bccda4] received
2022-05-17 07:02:23,285 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6a16bd68-44e0-4371-9f16-cf9d43bccda4] succeeded in 1.2907497980004337s: None
2022-05-17 07:17:22,000 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:17:22,002 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c453db08-4550-434d-a6e5-222d93f49b96] received
2022-05-17 07:17:23,290 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c453db08-4550-434d-a6e5-222d93f49b96] succeeded in 1.2859622500000114s: None
2022-05-17 07:32:22,008 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:32:22,011 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[59360a51-1dfe-4cfa-9b49-cf4fcf533073] received
2022-05-17 07:32:24,104 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[59360a51-1dfe-4cfa-9b49-cf4fcf533073] succeeded in 2.0916169669999363s: None
2022-05-17 07:47:22,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:47:22,019 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c62915fd-335b-4a64-9207-50be75b3dbf9] received
2022-05-17 07:47:24,196 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c62915fd-335b-4a64-9207-50be75b3dbf9] succeeded in 2.1744268399997964s: None
2022-05-17 08:02:22,021 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:02:22,022 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1eb05810-18b0-402c-a624-b610b4df4667] received
2022-05-17 08:02:23,564 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1eb05810-18b0-402c-a624-b610b4df4667] succeeded in 1.53949540099984s: None
2022-05-17 08:17:22,030 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:17:22,032 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b7e2a810-f9e1-4774-b549-18f07ab2394e] received
2022-05-17 08:17:24,241 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b7e2a810-f9e1-4774-b549-18f07ab2394e] succeeded in 2.2071988010002315s: None
2022-05-17 08:32:22,038 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:32:22,041 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e74b27f-e940-40bc-85d6-79eee0918823] received
2022-05-17 08:32:23,960 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e74b27f-e940-40bc-85d6-79eee0918823] succeeded in 1.9180154369996671s: None
2022-05-17 08:47:22,045 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:47:22,047 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[23b4be20-d895-4278-99d3-082ee6a86cdd] received
2022-05-17 08:47:23,596 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[23b4be20-d895-4278-99d3-082ee6a86cdd] succeeded in 1.5471598750009434s: None
2022-05-17 09:02:22,052 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:02:22,055 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0dfa6203-2b76-4a61-91e7-23d7746b6438] received
2022-05-17 09:02:27,965 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0dfa6203-2b76-4a61-91e7-23d7746b6438] succeeded in 5.908419228000639s: None
2022-05-17 09:17:22,055 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:17:22,057 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd032df5-5811-4802-9ea8-09e403186405] received
2022-05-17 09:17:24,530 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd032df5-5811-4802-9ea8-09e403186405] succeeded in 2.471370798000862s: None
2022-05-17 09:32:22,063 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:32:22,066 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4be6906d-80ec-4778-b470-7740959ce503] received
2022-05-17 09:32:23,141 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4be6906d-80ec-4778-b470-7740959ce503] succeeded in 1.0727636400006304s: None
2022-05-17 09:47:22,071 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:47:22,073 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd118ab7-778f-44c2-8b1e-2e8ca1a80ccf] received
2022-05-17 09:47:24,029 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd118ab7-778f-44c2-8b1e-2e8ca1a80ccf] succeeded in 1.9535806880012387s: None
2022-05-17 10:02:22,075 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:02:22,078 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9a259204-dcc7-482f-a827-50a7bfe6aad4] received
2022-05-17 10:02:23,121 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9a259204-dcc7-482f-a827-50a7bfe6aad4] succeeded in 1.041601491999245s: None
2022-05-17 10:17:22,083 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:17:22,086 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e2b74820-ee46-4d77-9c69-e1c052b5b963] received
2022-05-17 10:17:23,170 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e2b74820-ee46-4d77-9c69-e1c052b5b963] succeeded in 1.0824599210009183s: None
2022-05-17 10:32:22,091 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:32:22,094 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c4e02c56-1951-4661-b526-4e1f917aeda8] received
2022-05-17 10:32:23,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c4e02c56-1951-4661-b526-4e1f917aeda8] succeeded in 1.0520202419993439s: None
2022-05-17 10:47:22,099 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:47:22,101 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0d2edca-c976-4cde-8a00-33a25edb6b74] received
2022-05-17 10:47:23,212 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0d2edca-c976-4cde-8a00-33a25edb6b74] succeeded in 1.109383330000128s: None
2022-05-17 10:57:34,818 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 10:57:35,334 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 10:57:35,339 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 10:57:35,345 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 10:57:36,355 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 10:57:36,368 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 10:57:36,368 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 10:57:49,457 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 10:57:53,044 - celery.beat - INFO - beat: Starting...
2022-05-17 11:02:22,113 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:02:22,129 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c25ae071-4352-4262-aaf0-686a7320a103] received
2022-05-17 11:02:23,162 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c25ae071-4352-4262-aaf0-686a7320a103] succeeded in 1.0313276240012783s: None
2022-05-17 11:17:22,115 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:17:22,118 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b7684cdb-cea8-4e68-be6f-3a7985200f97] received
2022-05-17 11:17:23,095 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b7684cdb-cea8-4e68-be6f-3a7985200f97] succeeded in 0.9756028700030583s: None
2022-05-17 11:32:22,124 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:32:22,126 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b9987825-e325-49cd-b5aa-25af8fc75cdf] received
2022-05-17 11:32:23,228 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b9987825-e325-49cd-b5aa-25af8fc75cdf] succeeded in 1.1006480010000814s: None
2022-05-17 11:47:22,132 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:47:22,134 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4af424b8-f822-436f-85f9-31027feedca6] received
2022-05-17 11:47:23,075 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4af424b8-f822-436f-85f9-31027feedca6] succeeded in 0.9392859369982034s: None
2022-05-17 12:02:22,139 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:02:22,141 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2e9ee09f-1b90-425c-b980-d6ba0eab16f8] received
2022-05-17 12:02:23,127 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2e9ee09f-1b90-425c-b980-d6ba0eab16f8] succeeded in 0.9845981060025224s: None
2022-05-17 12:17:22,142 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:17:22,145 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eb201fa7-bc1c-4630-a548-186dee7457bc] received
2022-05-17 12:17:23,218 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eb201fa7-bc1c-4630-a548-186dee7457bc] succeeded in 1.0710584150001523s: None
2022-05-17 12:32:22,149 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:32:22,150 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b02b148c-d18f-401a-8c28-17cd6d8b9e75] received
2022-05-17 12:32:23,502 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b02b148c-d18f-401a-8c28-17cd6d8b9e75] succeeded in 1.3503611169981014s: None
2022-05-17 12:47:22,157 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:47:22,159 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7de17c85-6ac3-41a4-a731-43e82c9243ba] received
2022-05-17 12:47:23,472 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7de17c85-6ac3-41a4-a731-43e82c9243ba] succeeded in 1.3111561890000303s: None
2022-05-17 13:02:22,166 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:02:22,169 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5439f77c-a0b1-4bbf-a638-3951a1853c13] received
2022-05-17 13:02:23,210 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5439f77c-a0b1-4bbf-a638-3951a1853c13] succeeded in 1.039562317000673s: None
2022-05-17 13:17:22,174 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:17:22,177 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[635bfed8-ace1-4fb5-b56e-2c92735acabc] received
2022-05-17 13:17:23,388 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[635bfed8-ace1-4fb5-b56e-2c92735acabc] succeeded in 1.2091301740001654s: None
2022-05-17 13:32:22,180 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:32:22,183 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[92269ec5-d438-4a25-b10d-52f020d85caa] received
2022-05-17 13:32:23,535 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[92269ec5-d438-4a25-b10d-52f020d85caa] succeeded in 1.351578262001567s: None
2022-05-17 13:47:22,189 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:47:22,192 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[69931ba6-f111-45e7-80f1-dcbd68a31260] received
2022-05-17 13:47:24,060 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[69931ba6-f111-45e7-80f1-dcbd68a31260] succeeded in 1.8669047830007912s: None
2022-05-17 16:35:23,258 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 16:35:23,805 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 16:35:23,807 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 16:35:23,812 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 16:35:24,821 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 16:35:24,836 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 16:35:24,836 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 16:35:38,768 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 16:35:44,538 - celery.beat - INFO - beat: Starting...
2022-05-17 16:35:44,610 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 16:35:44,617 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9da69afd-a69d-4763-acfc-5e28f97f305e] received
2022-05-17 16:35:50,774 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9da69afd-a69d-4763-acfc-5e28f97f305e] succeeded in 6.15609538499848s: None
2022-05-17 16:50:44,616 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 16:50:44,619 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[66faba79-a634-4ead-93fd-9d4f1608e69c] received
2022-05-17 16:50:45,648 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[66faba79-a634-4ead-93fd-9d4f1608e69c] succeeded in 1.0282381200013333s: None
2022-05-17 17:04:51,972 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 17:04:52,496 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 17:04:52,499 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 17:04:52,505 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 17:04:53,512 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 17:04:53,523 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 17:04:53,523 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 17:04:58,806 - celery.beat - INFO - beat: Starting...
2022-05-17 17:05:00,320 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 17:05:44,627 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:05:44,642 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d0904bca-f1ab-4f00-ad58-b77536b7e977] received
2022-05-17 17:05:45,686 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d0904bca-f1ab-4f00-ad58-b77536b7e977] succeeded in 1.0418075699999463s: None
2022-05-17 17:20:44,629 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:20:44,634 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3ad4ba18-e378-4c97-bf0b-203548b6060b] received
2022-05-17 17:20:45,801 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3ad4ba18-e378-4c97-bf0b-203548b6060b] succeeded in 1.1655622859980213s: None
2022-05-17 17:35:44,631 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:35:44,633 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4bb93d39-611b-4859-b0bd-8a67d6178941] received
2022-05-17 17:35:45,485 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4bb93d39-611b-4859-b0bd-8a67d6178941] succeeded in 0.8505766739981482s: None
2022-05-17 17:50:44,635 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:50:44,637 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a524bd2-c183-43ee-af0f-d1d638c5c598] received
2022-05-17 17:50:45,662 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5a524bd2-c183-43ee-af0f-d1d638c5c598] succeeded in 1.0229675939990557s: None
2022-05-17 18:05:51,720 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 18:05:52,286 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 18:05:52,289 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 18:05:52,294 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 18:05:53,307 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 18:05:53,322 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 18:05:53,322 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 18:05:58,995 - celery.beat - INFO - beat: Starting...
2022-05-17 18:05:59,062 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 18:05:59,070 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b4f56fd9-17f5-44d2-8412-47fff0573634] received
2022-05-17 18:05:59,885 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b4f56fd9-17f5-44d2-8412-47fff0573634] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (107, null, f, 19, 2317).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (107, null, f, 19, 2317).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (107, null, f, 19, 2317).

2022-05-17 18:06:00,466 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 18:20:59,069 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 18:20:59,071 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a49ebf63-2040-4db2-a514-3b416970ad41] received
2022-05-17 18:20:59,829 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a49ebf63-2040-4db2-a514-3b416970ad41] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (108, null, f, 19, 2318).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (108, null, f, 19, 2318).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (108, null, f, 19, 2318).

2022-05-17 20:19:32,232 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:19:32,750 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:19:32,754 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:19:32,760 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:19:33,771 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:19:33,786 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:19:33,787 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:19:49,451 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:19:53,280 - celery.beat - INFO - beat: Starting...
2022-05-17 20:19:53,347 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:19:53,356 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae0573cc-b590-4fc4-b5a3-9548a9d21da6] received
2022-05-17 20:19:54,838 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[ae0573cc-b590-4fc4-b5a3-9548a9d21da6] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (109, null, f, 20, 2320).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (109, null, f, 20, 2320).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (109, null, f, 20, 2320).

2022-05-17 20:35:58,009 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:35:58,521 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:35:58,525 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:35:58,532 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:35:59,543 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:35:59,558 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:35:59,558 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:36:07,311 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:36:12,043 - celery.beat - INFO - beat: Starting...
2022-05-17 20:36:12,109 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:36:12,116 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8733b9e6-4e17-47e3-aef2-080f3ce6a40c] received
2022-05-17 20:36:12,897 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8733b9e6-4e17-47e3-aef2-080f3ce6a40c] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (110, null, f, 20, 2325).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (110, null, f, 20, 2325).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article, pub_date)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (110, null, f, 20, 2325).

2022-05-17 20:42:58,420 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:42:58,938 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:42:58,944 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:42:58,949 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:42:59,959 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:42:59,972 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:42:59,972 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:43:05,021 - celery.beat - INFO - beat: Starting...
2022-05-17 20:43:06,739 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:51:12,111 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:51:12,125 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[461d92b1-ac83-42ab-9f3f-75a3e358f8db] received
2022-05-17 20:51:18,528 - celery.redirected - WARNING - 2022-05-17 18:06:08+00:00
2022-05-17 20:51:18,547 - celery.redirected - WARNING - 2022-05-17 17:53:51+00:00
2022-05-17 20:51:18,611 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[461d92b1-ac83-42ab-9f3f-75a3e358f8db] succeeded in 6.484946562995901s: None
2022-05-17 21:06:12,117 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:06:12,119 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8430c560-68d3-41ca-bd05-5f96e98a0f63] received
2022-05-17 21:06:13,209 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8430c560-68d3-41ca-bd05-5f96e98a0f63] succeeded in 1.0880261880010949s: None
2022-05-17 21:21:12,125 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:21:12,127 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[913c67aa-c3be-43dc-a183-5b142874479a] received
2022-05-17 21:21:13,105 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[913c67aa-c3be-43dc-a183-5b142874479a] succeeded in 0.9765800169989234s: None
2022-05-17 21:36:12,132 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:36:12,135 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7b994df5-0428-4318-88ce-d219f0c2933b] received
2022-05-17 21:36:13,533 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7b994df5-0428-4318-88ce-d219f0c2933b] succeeded in 1.397149760996399s: None
2022-05-17 21:51:12,141 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:51:12,144 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[96651389-1034-43a7-8675-2fbcd956fa2f] received
2022-05-17 21:51:12,997 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[96651389-1034-43a7-8675-2fbcd956fa2f] succeeded in 0.8520542379992548s: None
2022-05-17 22:06:12,151 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 22:06:12,154 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b91f3465-8cc5-462f-96c3-af25f817ced6] received
2022-05-17 22:06:13,156 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b91f3465-8cc5-462f-96c3-af25f817ced6] succeeded in 1.0005229800008237s: None
2022-05-18 06:36:59,856 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-18 06:37:00,366 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-18 06:37:00,370 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-18 06:37:00,374 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-18 06:37:01,384 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-18 06:37:01,406 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-18 06:37:01,406 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-18 06:37:14,291 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-18 06:37:54,654 - celery.beat - INFO - beat: Starting...
2022-05-18 06:37:54,724 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 06:37:54,737 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ebf2ec92-9705-4510-9f68-a0b67848651f] received
2022-05-18 06:37:55,834 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[ebf2ec92-9705-4510-9f68-a0b67848651f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 06:52:54,724 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 06:52:54,726 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[43fb22dc-2b56-4b78-b1e1-3411adb4d5b8] received
2022-05-18 06:52:55,532 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[43fb22dc-2b56-4b78-b1e1-3411adb4d5b8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:07:54,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:07:54,736 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bf7178ad-e6a6-4737-971d-e4e430846397] received
2022-05-18 07:07:55,642 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[bf7178ad-e6a6-4737-971d-e4e430846397] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:22:54,747 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:22:54,749 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f1d7d45c-cf4e-4166-92e5-a215fa855120] received
2022-05-18 07:22:55,566 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f1d7d45c-cf4e-4166-92e5-a215fa855120] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:37:54,750 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:37:54,751 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[53b70408-7574-4545-8da2-6172809b68aa] received
2022-05-18 07:37:55,708 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[53b70408-7574-4545-8da2-6172809b68aa] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:52:54,758 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:52:54,760 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8f678947-3f00-41b0-bb85-e57a76ffad0c] received
2022-05-18 07:52:55,843 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8f678947-3f00-41b0-bb85-e57a76ffad0c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:07:54,761 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:07:54,763 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a595db1f-732b-4116-83dd-6c07f80b2fda] received
2022-05-18 08:07:56,001 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a595db1f-732b-4116-83dd-6c07f80b2fda] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:22:54,770 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:22:54,772 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9c116b1f-9d9c-4503-8d79-2e5c1ed63239] received
2022-05-18 08:22:56,015 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[9c116b1f-9d9c-4503-8d79-2e5c1ed63239] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:37:54,775 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:37:54,777 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a860e14-cd60-4109-a57a-cdb60a4607b5] received
2022-05-18 08:37:55,711 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5a860e14-cd60-4109-a57a-cdb60a4607b5] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:52:54,784 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:52:54,786 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e7154151-aada-4aed-9c1c-7bd10c69b9f5] received
2022-05-18 08:52:55,788 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e7154151-aada-4aed-9c1c-7bd10c69b9f5] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:07:54,792 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:07:54,794 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6525337a-28cc-46a0-9d02-de57f384b6c6] received
2022-05-18 09:07:55,943 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[6525337a-28cc-46a0-9d02-de57f384b6c6] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:22:54,801 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:22:54,803 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9e58f911-ce12-4dc7-80a3-4ea7f26b2b79] received
2022-05-18 09:22:55,791 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[9e58f911-ce12-4dc7-80a3-4ea7f26b2b79] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:37:54,809 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:37:54,812 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[505f2b36-158e-4ae9-84f8-a28262180381] received
2022-05-18 09:37:55,782 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[505f2b36-158e-4ae9-84f8-a28262180381] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:52:54,811 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:52:54,813 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2016f83d-a149-4e0c-b712-ffc1d1e3a454] received
2022-05-18 09:52:55,830 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[2016f83d-a149-4e0c-b712-ffc1d1e3a454] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:07:54,811 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:07:54,813 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c44564b9-371c-46c4-b560-e81c1c5c3158] received
2022-05-18 10:07:55,877 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[c44564b9-371c-46c4-b560-e81c1c5c3158] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:22:54,820 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:22:54,824 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[84e270de-ae8b-408f-96ca-6a76495e3406] received
2022-05-18 10:22:55,856 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[84e270de-ae8b-408f-96ca-6a76495e3406] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:37:54,828 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:37:54,830 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1f0e4011-4948-42fe-8e89-5b2055daadbf] received
2022-05-18 10:37:55,845 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1f0e4011-4948-42fe-8e89-5b2055daadbf] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:52:54,839 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:52:54,842 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f6082b3a-66cd-4134-9e41-d8bdedeb0804] received
2022-05-18 10:52:56,037 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f6082b3a-66cd-4134-9e41-d8bdedeb0804] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:07:54,848 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:07:54,851 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e767b9f5-e158-485d-8164-4ec5e3acd394] received
2022-05-18 11:07:55,836 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e767b9f5-e158-485d-8164-4ec5e3acd394] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:22:54,856 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:22:54,860 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f580b7f2-9a00-4081-b85d-8f0d1c452305] received
2022-05-18 11:22:55,798 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f580b7f2-9a00-4081-b85d-8f0d1c452305] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:37:54,866 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:37:54,868 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e6016a48-d562-45ba-abbd-78af2188b73f] received
2022-05-18 11:37:55,830 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e6016a48-d562-45ba-abbd-78af2188b73f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:52:54,868 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:52:54,870 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5233d62e-5322-4602-919a-a2132088e91c] received
2022-05-18 11:52:55,772 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5233d62e-5322-4602-919a-a2132088e91c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:07:54,877 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:07:54,878 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[834a769c-5478-4aa0-a8a7-54de02d51660] received
2022-05-18 12:07:55,822 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[834a769c-5478-4aa0-a8a7-54de02d51660] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:22:54,885 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:22:54,887 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[aade3019-9196-43ab-b8e1-24b1d72ccac8] received
2022-05-18 12:22:55,937 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[aade3019-9196-43ab-b8e1-24b1d72ccac8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:37:54,894 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:37:54,896 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1de6f478-e8e4-4c93-b92f-c3eeb3ba1033] received
2022-05-18 12:37:55,868 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1de6f478-e8e4-4c93-b92f-c3eeb3ba1033] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:52:54,903 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:52:54,907 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6a77ddc2-de3a-4540-a8db-7216dcf0b112] received
2022-05-18 12:52:55,849 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[6a77ddc2-de3a-4540-a8db-7216dcf0b112] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:07:54,912 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:07:54,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[40b3feee-23f7-406a-bf47-ea08ec05aac2] received
2022-05-18 13:07:55,982 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[40b3feee-23f7-406a-bf47-ea08ec05aac2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:22:54,918 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:22:54,921 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1a882d3b-2ade-4024-ae4d-324ce9c7ac1d] received
2022-05-18 13:22:55,926 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1a882d3b-2ade-4024-ae4d-324ce9c7ac1d] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:37:54,922 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:37:54,924 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8989ee98-06c1-4ef5-86a4-17489c721745] received
2022-05-18 13:37:55,913 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8989ee98-06c1-4ef5-86a4-17489c721745] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:52:54,930 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:52:54,932 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e6cb443-0589-47bd-8325-80d64e80de00] received
2022-05-18 13:52:55,987 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4e6cb443-0589-47bd-8325-80d64e80de00] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 14:07:54,937 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 14:07:54,939 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8637b635-0862-4828-9e14-b6b975b96feb] received
2022-05-18 14:07:55,818 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8637b635-0862-4828-9e14-b6b975b96feb] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 06:42:04,533 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 06:42:05,041 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 06:42:05,047 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 06:42:05,053 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 06:42:06,065 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 06:42:06,082 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 06:42:06,083 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 06:42:21,804 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 06:42:27,011 - celery.beat - INFO - beat: Starting...
2022-05-19 06:42:27,089 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 06:42:27,100 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4b3e4058-90e3-4c3a-ae5f-6eccb3d99536] received
2022-05-19 06:42:28,885 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4b3e4058-90e3-4c3a-ae5f-6eccb3d99536] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 06:57:27,088 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 06:57:27,089 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a73e3fd1-7b0e-4650-ba28-2135a56f2b6e] received
2022-05-19 06:57:28,043 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a73e3fd1-7b0e-4650-ba28-2135a56f2b6e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:12:27,096 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:12:27,099 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1d257a91-967e-4b7c-8169-48bb1adbc0f4] received
2022-05-19 07:12:28,056 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1d257a91-967e-4b7c-8169-48bb1adbc0f4] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:27:27,105 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:27:27,108 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b32b0a38-a0a5-47f8-b846-ab1d118dc11a] received
2022-05-19 07:27:28,205 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b32b0a38-a0a5-47f8-b846-ab1d118dc11a] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:42:27,114 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:42:27,116 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cfa03abd-5c7e-4c5e-bc0c-17a1d9cb5ebe] received
2022-05-19 07:42:28,103 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[cfa03abd-5c7e-4c5e-bc0c-17a1d9cb5ebe] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:57:27,122 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:57:27,125 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[672c8d79-d1d9-4d7c-beeb-afed89bedc9e] received
2022-05-19 07:57:28,147 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[672c8d79-d1d9-4d7c-beeb-afed89bedc9e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:12:27,124 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:12:27,126 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[639f15f3-d2a0-4bff-bcbd-83c70bb15d8f] received
2022-05-19 08:12:28,188 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[639f15f3-d2a0-4bff-bcbd-83c70bb15d8f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:27:27,133 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:27:27,136 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[286fec76-b505-4d29-8e17-8693752db07e] received
2022-05-19 08:27:29,231 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[286fec76-b505-4d29-8e17-8693752db07e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:42:27,142 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:42:27,143 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[912dca9a-91b7-4764-be33-5cb0b173b404] received
2022-05-19 08:42:28,083 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[912dca9a-91b7-4764-be33-5cb0b173b404] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:57:27,146 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:57:27,148 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[99e19d36-2b6d-4827-8ac6-e8d340ecf57c] received
2022-05-19 08:57:28,171 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[99e19d36-2b6d-4827-8ac6-e8d340ecf57c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:12:27,150 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:12:27,151 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8c20fe78-61f7-451c-8086-cf5e33568cbe] received
2022-05-19 09:12:28,214 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8c20fe78-61f7-451c-8086-cf5e33568cbe] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:27:27,155 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:27:27,157 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4b4f15de-1194-4aa4-924d-e7fa9dbc3ae6] received
2022-05-19 09:27:28,260 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4b4f15de-1194-4aa4-924d-e7fa9dbc3ae6] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    print(type(datetime.now))
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:42:27,163 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:42:27,166 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5d68c51f-8069-4fe0-b7f7-dd0ec43d3de2] received
2022-05-19 09:42:28,204 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5d68c51f-8069-4fe0-b7f7-dd0ec43d3de2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:57:27,172 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:57:27,175 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ffdfba9-24cd-4343-9941-b75b3aee0ab8] received
2022-05-19 09:57:28,348 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[7ffdfba9-24cd-4343-9941-b75b3aee0ab8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 10:11:50,673 - django_celery_beat.schedulers - INFO - DatabaseScheduler: Schedule changed.
2022-05-19 10:11:50,723 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:11:50,725 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2c1a012-db08-44bd-a1f1-f36042b600b2] received
2022-05-19 10:11:51,755 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[d2c1a012-db08-44bd-a1f1-f36042b600b2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 10:11:55,755 - django_celery_beat.schedulers - INFO - DatabaseScheduler: Schedule changed.
2022-05-19 10:12:13,565 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:12:14,082 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 10:12:14,086 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 10:12:14,091 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:12:15,102 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 10:12:15,115 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 10:12:15,115 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 10:12:20,408 - celery.beat - INFO - beat: Starting...
2022-05-19 10:12:22,199 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 10:16:50,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:16:50,751 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4989d4d4-ad91-4038-a151-9a83ade28b9b] received
2022-05-19 10:16:51,647 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4989d4d4-ad91-4038-a151-9a83ade28b9b] succeeded in 0.8944745949993376s: None
2022-05-19 10:22:23,375 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:22:23,897 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 10:22:23,900 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 10:22:23,903 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:22:24,914 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 10:22:24,937 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 10:22:24,937 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 10:22:32,273 - celery.beat - INFO - beat: Starting...
2022-05-19 10:22:32,342 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:22:32,350 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd7443ec-fcf0-4707-8e1e-960b38fe3e30] received
2022-05-19 10:22:33,448 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd7443ec-fcf0-4707-8e1e-960b38fe3e30] succeeded in 1.0972006739993958s: None
2022-05-19 10:22:33,895 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 10:27:32,349 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:27:32,352 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eaf50e5a-8f14-4a40-b3bb-b35f45e0e225] received
2022-05-19 10:27:32,764 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eaf50e5a-8f14-4a40-b3bb-b35f45e0e225] succeeded in 0.4101717550001922s: None
2022-05-19 10:32:32,357 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:32:32,359 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ec72401b-0e31-485b-bce4-fa4e6bf98f88] received
2022-05-19 10:32:32,822 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ec72401b-0e31-485b-bce4-fa4e6bf98f88] succeeded in 0.4615866989988717s: None
2022-05-19 10:37:32,369 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:37:32,371 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[111ed8db-9496-425c-abf3-10d17286f7bb] received
2022-05-19 10:37:32,722 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[111ed8db-9496-425c-abf3-10d17286f7bb] succeeded in 0.34929178099991987s: None
2022-05-19 10:42:32,375 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:42:32,377 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c3693873-21f6-4ce6-8617-46a98c098bf8] received
2022-05-19 10:42:32,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c3693873-21f6-4ce6-8617-46a98c098bf8] succeeded in 0.48164794399963284s: None
2022-05-19 10:47:32,386 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:47:32,389 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[08824d01-b9c4-483a-a42b-8a4d4df09229] received
2022-05-19 10:47:32,821 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[08824d01-b9c4-483a-a42b-8a4d4df09229] succeeded in 0.43049878500096384s: None
2022-05-19 10:52:32,395 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:52:32,398 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[25309756-9a21-4fea-a9a9-2bebdfb6606d] received
2022-05-19 10:52:32,746 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[25309756-9a21-4fea-a9a9-2bebdfb6606d] succeeded in 0.34643885500190663s: None
2022-05-19 10:57:32,405 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:57:32,408 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7a3486f1-b1e1-4f2b-bad6-3e0875601bb0] received
2022-05-19 10:57:32,887 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7a3486f1-b1e1-4f2b-bad6-3e0875601bb0] succeeded in 0.4777644470013911s: None
2022-05-19 11:02:32,412 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:02:32,413 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a926472e-6878-4306-9e93-4567ccc27105] received
2022-05-19 11:02:32,822 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a926472e-6878-4306-9e93-4567ccc27105] succeeded in 0.4081360210002458s: None
2022-05-19 11:07:32,418 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:07:32,421 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0b215689-8d3b-4407-9611-d1c97509a0d1] received
2022-05-19 11:07:32,836 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0b215689-8d3b-4407-9611-d1c97509a0d1] succeeded in 0.413604639001278s: None
2022-05-19 11:12:32,425 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:12:32,427 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[43433073-6836-4a3b-83f7-0ddf49a69cfd] received
2022-05-19 11:12:32,873 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[43433073-6836-4a3b-83f7-0ddf49a69cfd] succeeded in 0.44435993599836365s: None
2022-05-19 11:17:32,432 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:17:32,434 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8b94a4dd-8e85-47c2-a9bd-bf6b52533b6d] received
2022-05-19 11:17:32,831 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8b94a4dd-8e85-47c2-a9bd-bf6b52533b6d] succeeded in 0.39544836999994004s: None
2022-05-19 11:22:32,443 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:22:32,445 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[69f6f0ef-2b20-4f55-8fac-8b2abd61e39a] received
2022-05-19 11:22:32,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[69f6f0ef-2b20-4f55-8fac-8b2abd61e39a] succeeded in 0.4130063450029411s: None
2022-05-19 11:27:32,453 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:27:32,455 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[03f42a0f-af80-4f74-bf1f-015ca353277a] received
2022-05-19 11:27:32,891 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[03f42a0f-af80-4f74-bf1f-015ca353277a] succeeded in 0.4343491699983133s: None
2022-05-19 11:32:32,464 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:32:32,466 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[13019020-587c-4ebe-be9d-2a8af6a993b6] received
2022-05-19 11:32:32,841 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[13019020-587c-4ebe-be9d-2a8af6a993b6] succeeded in 0.37361244200292276s: None
2022-05-19 11:37:32,474 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:37:32,477 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0bcd53bb-b95e-4d41-81c3-29072510bcfc] received
2022-05-19 11:37:32,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0bcd53bb-b95e-4d41-81c3-29072510bcfc] succeeded in 0.4829934859990317s: None
2022-05-19 11:42:32,485 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:42:32,490 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[60ec132b-6e69-4188-9a54-ca97c98bc4a6] received
2022-05-19 11:42:32,895 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[60ec132b-6e69-4188-9a54-ca97c98bc4a6] succeeded in 0.40345216100104153s: None
2022-05-19 11:47:32,492 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:47:32,494 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[edbd0428-acc7-45f9-82e2-63500d5c36a8] received
2022-05-19 11:47:32,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[edbd0428-acc7-45f9-82e2-63500d5c36a8] succeeded in 0.46629632999975s: None
2022-05-19 11:52:32,497 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:52:32,499 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6fc26af9-3831-471b-9d06-6f856018a20f] received
2022-05-19 11:52:32,871 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6fc26af9-3831-471b-9d06-6f856018a20f] succeeded in 0.3713765450011124s: None
2022-05-19 11:57:32,502 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:57:32,505 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[18c8ac4b-5dd0-4062-84b5-a0e4d585d837] received
2022-05-19 11:57:32,841 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[18c8ac4b-5dd0-4062-84b5-a0e4d585d837] succeeded in 0.3352656589995604s: None
2022-05-19 12:02:32,505 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:02:32,507 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3fe5fe02-94d6-402c-a304-7fd79a49141a] received
2022-05-19 12:02:32,934 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3fe5fe02-94d6-402c-a304-7fd79a49141a] succeeded in 0.4256230070022866s: None
2022-05-19 12:07:32,512 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:07:32,515 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[13c53cf0-5236-4a89-a900-a41196ec653a] received
2022-05-19 12:07:32,852 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[13c53cf0-5236-4a89-a900-a41196ec653a] succeeded in 0.3348443139984738s: None
2022-05-19 12:12:32,523 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:12:32,525 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6c324536-bf0d-4078-9d24-433f0c695779] received
2022-05-19 12:12:32,894 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6c324536-bf0d-4078-9d24-433f0c695779] succeeded in 0.36703133799892385s: None
2022-05-19 12:17:32,534 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:17:32,537 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[89436e5f-b467-4db6-8000-0a1614adac18] received
2022-05-19 12:17:32,915 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[89436e5f-b467-4db6-8000-0a1614adac18] succeeded in 0.3763169949997973s: None
2022-05-19 12:22:32,544 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:22:32,547 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d8d15d31-afee-4a84-8ad0-89313d60fe27] received
2022-05-19 12:22:32,969 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d8d15d31-afee-4a84-8ad0-89313d60fe27] succeeded in 0.4207596800006286s: None
2022-05-19 12:27:32,555 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:27:32,557 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2d6fe6a4-ba4c-4be9-b933-284b25f0124c] received
2022-05-19 12:27:32,945 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2d6fe6a4-ba4c-4be9-b933-284b25f0124c] succeeded in 0.3872592869993241s: None
2022-05-19 12:32:32,561 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:32:32,562 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[af878a49-1277-48a1-86c4-c429cb4c2781] received
2022-05-19 12:32:33,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[af878a49-1277-48a1-86c4-c429cb4c2781] succeeded in 0.5837670359978802s: None
2022-05-19 12:37:32,572 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:37:32,574 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[21515e9c-d604-4792-99ad-bffc3617537b] received
2022-05-19 12:37:33,078 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[21515e9c-d604-4792-99ad-bffc3617537b] succeeded in 0.5024682839975867s: None
2022-05-19 12:42:32,583 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:42:32,585 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f7c0aca5-2c98-4933-bac6-c71e8367e657] received
2022-05-19 12:42:33,065 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f7c0aca5-2c98-4933-bac6-c71e8367e657] succeeded in 0.4782116019996465s: None
2022-05-19 12:47:32,591 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:47:32,593 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e6befd41-3e03-44d3-859c-be551cb7ffb7] received
2022-05-19 12:47:38,282 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e6befd41-3e03-44d3-859c-be551cb7ffb7] succeeded in 5.688534054999764s: None
2022-05-19 12:52:32,598 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:52:32,600 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6198868c-76ba-4a97-a21d-af44dc625af2] received
2022-05-19 12:52:33,088 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6198868c-76ba-4a97-a21d-af44dc625af2] succeeded in 0.4861804400024994s: None
2022-05-19 12:57:32,599 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:57:32,601 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ff0b7c3b-cd79-4de7-8ef2-981b10d24101] received
2022-05-19 12:57:33,011 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ff0b7c3b-cd79-4de7-8ef2-981b10d24101] succeeded in 0.40907317900200724s: None
2022-05-19 13:02:32,606 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:02:32,608 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[00f4316b-3c8a-4968-b6d2-5d811b73e689] received
2022-05-19 13:02:39,216 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[00f4316b-3c8a-4968-b6d2-5d811b73e689] succeeded in 6.604910859998199s: None
2022-05-19 13:07:32,617 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:07:32,621 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ef7ebf53-3a70-4af8-a9f3-50f1f4d9c735] received
2022-05-19 13:07:33,075 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ef7ebf53-3a70-4af8-a9f3-50f1f4d9c735] succeeded in 0.4525791369997023s: None
2022-05-19 13:12:32,621 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:12:32,623 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9b35e6bf-9761-4ddc-b4bb-ad865356d6e2] received
2022-05-19 13:12:33,342 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9b35e6bf-9761-4ddc-b4bb-ad865356d6e2] succeeded in 0.7180221140006324s: None
2022-05-19 13:17:32,631 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:17:32,633 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bb5e9354-8e17-4fa5-a7a9-af55e38ba795] received
2022-05-19 13:17:33,184 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[bb5e9354-8e17-4fa5-a7a9-af55e38ba795] succeeded in 0.5495175219984958s: None
2022-05-19 13:22:32,637 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:22:32,640 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eb7d1808-0ed7-45e0-bbac-19124ad0471e] received
2022-05-19 13:22:33,090 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eb7d1808-0ed7-45e0-bbac-19124ad0471e] succeeded in 0.4493527759987046s: None
2022-05-19 13:27:32,645 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:27:32,648 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7223ac72-20f7-4f62-b22b-1605d68d64c0] received
2022-05-19 13:27:33,146 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7223ac72-20f7-4f62-b22b-1605d68d64c0] succeeded in 0.4967156589991646s: None
2022-05-19 13:32:32,648 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:32:32,650 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0f37010-498c-4d70-8ee9-e6814a10b985] received
2022-05-19 13:32:33,050 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0f37010-498c-4d70-8ee9-e6814a10b985] succeeded in 0.3990069730025425s: None
2022-05-19 13:37:32,655 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:37:32,659 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d882bfb9-03cf-4a28-a557-9ad005629e7f] received
2022-05-19 13:37:33,229 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d882bfb9-03cf-4a28-a557-9ad005629e7f] succeeded in 0.5696362939997925s: None
2022-05-19 13:42:32,666 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:42:32,669 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bd1e0dd6-2f3e-4613-9774-5a69964b23b6] received
2022-05-19 13:42:33,153 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[bd1e0dd6-2f3e-4613-9774-5a69964b23b6] succeeded in 0.4824860709995846s: None
2022-05-19 13:47:32,677 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:47:32,682 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d4f067b2-82a2-496a-899e-e72e484efe0f] received
2022-05-19 13:47:33,287 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d4f067b2-82a2-496a-899e-e72e484efe0f] succeeded in 0.6039991529978579s: None
2022-05-19 13:52:32,688 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:52:32,691 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c8ad40f6-8019-4996-a247-902614dc0b24] received
2022-05-19 13:52:33,159 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c8ad40f6-8019-4996-a247-902614dc0b24] succeeded in 0.4667781290008861s: None
2022-05-19 13:57:32,700 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 13:57:32,702 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b6ee822c-703b-4d19-8fc0-3003e37e333e] received
2022-05-19 13:57:33,389 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b6ee822c-703b-4d19-8fc0-3003e37e333e] succeeded in 0.6848145589974592s: None
2022-05-19 14:02:32,711 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:02:32,713 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8c593a53-3480-49d0-abaa-fb2245fff2c1] received
2022-05-19 14:02:33,253 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8c593a53-3480-49d0-abaa-fb2245fff2c1] succeeded in 0.5395426380018762s: None
2022-05-19 14:07:32,717 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:07:32,719 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[02641c19-5b1a-49e0-a2b3-ff0638c78fdb] received
2022-05-19 14:07:33,269 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[02641c19-5b1a-49e0-a2b3-ff0638c78fdb] succeeded in 0.5485283039997739s: None
2022-05-19 14:12:32,729 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:12:32,731 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[168b29e0-9418-427b-b965-af1cba860f16] received
2022-05-19 14:12:33,288 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[168b29e0-9418-427b-b965-af1cba860f16] succeeded in 0.5549494070000947s: None
2022-05-19 14:17:32,737 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:17:32,739 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[586a2c01-64ec-430e-8529-bd58b836d68b] received
2022-05-19 14:17:33,204 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[586a2c01-64ec-430e-8529-bd58b836d68b] succeeded in 0.46399514700169675s: None
2022-05-19 14:22:32,742 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:22:32,744 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d6b46815-302f-481f-b5be-7747d51ce2eb] received
2022-05-19 14:22:33,150 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d6b46815-302f-481f-b5be-7747d51ce2eb] succeeded in 0.4047129809987382s: None
2022-05-19 14:27:32,752 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:27:32,755 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ed8a32c9-196b-4611-89f9-6da14e926919] received
2022-05-19 14:27:33,221 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ed8a32c9-196b-4611-89f9-6da14e926919] succeeded in 0.4649026209990552s: None
2022-05-19 14:32:32,764 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:32:32,766 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6c210728-25f3-49c6-b02e-d645d826995f] received
2022-05-19 14:32:33,341 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6c210728-25f3-49c6-b02e-d645d826995f] succeeded in 0.5735670899994147s: None
2022-05-19 14:37:32,779 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:37:32,782 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[594eadf6-44be-47be-b0cd-c66873af0aa1] received
2022-05-19 14:37:33,254 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[594eadf6-44be-47be-b0cd-c66873af0aa1] succeeded in 0.4709599439993326s: None
2022-05-19 14:42:32,790 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:42:32,792 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[55539d85-cd05-4a76-850d-35410f89f655] received
2022-05-19 14:42:33,187 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[55539d85-cd05-4a76-850d-35410f89f655] succeeded in 0.3935128049997729s: None
2022-05-19 14:47:32,799 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:47:32,801 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6218d6cc-e003-4051-a92b-412bee61e915] received
2022-05-19 14:47:33,249 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6218d6cc-e003-4051-a92b-412bee61e915] succeeded in 0.4461781659992994s: None
2022-05-19 14:52:32,809 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:52:32,812 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a82d0ee7-8977-41cd-a99e-914ced622e77] received
2022-05-19 14:52:33,253 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a82d0ee7-8977-41cd-a99e-914ced622e77] succeeded in 0.43943260299784015s: None
2022-05-19 14:57:32,820 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 14:57:32,822 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d67a5045-a1d4-4d76-9740-db826029e953] received
2022-05-19 14:57:33,179 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d67a5045-a1d4-4d76-9740-db826029e953] succeeded in 0.3558041219985171s: None
2022-05-19 15:02:32,831 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:02:32,834 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e14f0ff9-6812-4984-93bf-c880769b0c37] received
2022-05-19 15:02:33,329 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e14f0ff9-6812-4984-93bf-c880769b0c37] succeeded in 0.4933050630024809s: None
2022-05-19 15:07:32,842 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:07:32,844 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c23d20e2-24ed-4470-9c69-0de7e59c18a4] received
2022-05-19 15:07:33,346 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c23d20e2-24ed-4470-9c69-0de7e59c18a4] succeeded in 0.5001703380003164s: None
2022-05-19 15:12:32,853 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:12:32,855 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8245b84b-04f4-4937-994a-4931721108e1] received
2022-05-19 15:12:33,368 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8245b84b-04f4-4937-994a-4931721108e1] succeeded in 0.511184492999746s: None
2022-05-19 15:17:32,864 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:17:32,866 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[03d684df-ad9d-4dd3-8e18-35c4756c35fb] received
2022-05-19 15:17:33,309 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[03d684df-ad9d-4dd3-8e18-35c4756c35fb] succeeded in 0.440893735998543s: None
2022-05-19 15:22:32,874 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:22:32,877 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5bd6a233-cbf6-4941-8038-f54ed4fe5dde] received
2022-05-19 15:22:33,352 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5bd6a233-cbf6-4941-8038-f54ed4fe5dde] succeeded in 0.47386719600035576s: None
2022-05-19 15:27:32,885 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:27:32,888 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[36656df0-53b1-4704-a45a-505478fed369] received
2022-05-19 15:27:33,259 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[36656df0-53b1-4704-a45a-505478fed369] succeeded in 0.369459410001582s: None
2022-05-19 15:32:32,897 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:32:32,899 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1c7ead55-abdb-4c1c-a6f8-d0f033de4808] received
2022-05-19 15:32:33,407 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1c7ead55-abdb-4c1c-a6f8-d0f033de4808] succeeded in 0.5065114370008814s: None
2022-05-19 15:37:32,907 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:37:32,909 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c3670fb7-093d-4178-aa43-dd0255ee22b1] received
2022-05-19 15:37:33,350 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c3670fb7-093d-4178-aa43-dd0255ee22b1] succeeded in 0.4391713069999241s: None
2022-05-19 15:42:32,909 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:42:32,910 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a3560391-5a3c-475a-bf8a-61e7ac46b3a3] received
2022-05-19 15:42:33,431 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a3560391-5a3c-475a-bf8a-61e7ac46b3a3] succeeded in 0.5196730320021743s: None
2022-05-19 15:47:32,911 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:47:32,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4b21e286-294a-42a2-9640-42bdfcb3ff16] received
2022-05-19 15:47:33,439 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4b21e286-294a-42a2-9640-42bdfcb3ff16] succeeded in 0.5236748570023337s: None
2022-05-19 15:52:32,913 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:52:32,917 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[37d0aee4-7283-45f8-bf9b-ffba08df246b] received
2022-05-19 15:52:33,398 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[37d0aee4-7283-45f8-bf9b-ffba08df246b] succeeded in 0.4797540770014166s: None
2022-05-19 15:57:32,923 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 15:57:32,925 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9662f3ac-cb33-4f8f-884e-4c8112f4b7ed] received
2022-05-19 15:57:33,509 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9662f3ac-cb33-4f8f-884e-4c8112f4b7ed] succeeded in 0.5824024450048455s: None
2022-05-19 16:02:32,933 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:02:32,936 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[df43e211-3251-4959-af2f-1db897380abd] received
2022-05-19 16:02:33,451 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[df43e211-3251-4959-af2f-1db897380abd] succeeded in 0.5137333669990767s: None
2022-05-19 16:07:32,943 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:07:32,945 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a4652ecf-74d1-4544-bd05-86d7355f43a5] received
2022-05-19 16:07:33,520 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a4652ecf-74d1-4544-bd05-86d7355f43a5] succeeded in 0.5733320030049072s: None
2022-05-19 16:12:32,950 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:12:32,951 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0e2e41e4-e731-4ffd-9d96-1b84eebd9197] received
2022-05-19 16:12:33,438 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0e2e41e4-e731-4ffd-9d96-1b84eebd9197] succeeded in 0.48518117100320524s: None
2022-05-19 16:17:32,957 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:17:32,958 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cc2c8391-3433-44ba-a1f8-e414194c66a9] received
2022-05-19 16:17:33,449 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cc2c8391-3433-44ba-a1f8-e414194c66a9] succeeded in 0.48922940700140316s: None
2022-05-19 16:22:32,966 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:22:32,969 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e5dac946-4342-4796-a3fd-9ff1775e9faa] received
2022-05-19 16:22:33,461 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e5dac946-4342-4796-a3fd-9ff1775e9faa] succeeded in 0.4905344029975822s: None
2022-05-19 16:27:32,976 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:27:32,980 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[181d62be-3b3e-41f0-b1b7-2814d180a18e] received
2022-05-19 16:27:33,547 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[181d62be-3b3e-41f0-b1b7-2814d180a18e] succeeded in 0.56532667799911s: None
2022-05-19 16:32:32,983 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:32:32,985 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[36d4da25-3bc0-4aa3-b688-6eaa0770ca19] received
2022-05-19 16:32:33,669 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[36d4da25-3bc0-4aa3-b688-6eaa0770ca19] succeeded in 0.6836029909973149s: None
2022-05-19 16:37:32,995 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:37:32,997 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9bb21662-cb22-40db-aac2-0dbf5b2c8fa9] received
2022-05-19 16:37:33,609 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9bb21662-cb22-40db-aac2-0dbf5b2c8fa9] succeeded in 0.6103276659996482s: None
2022-05-19 16:42:33,006 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:42:33,010 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8df3129d-40fd-468f-aeb6-7c97306b4f10] received
2022-05-19 16:42:33,556 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8df3129d-40fd-468f-aeb6-7c97306b4f10] succeeded in 0.5437680920003913s: None
2022-05-19 16:47:33,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:47:33,020 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b7254b5-e560-41eb-b23e-2d5e18f16022] received
2022-05-19 16:47:33,489 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b7254b5-e560-41eb-b23e-2d5e18f16022] succeeded in 0.4671277539964649s: None
2022-05-19 16:52:33,029 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:52:33,031 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4d165823-9096-4652-b131-09cce4464a8b] received
2022-05-19 16:52:33,542 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4d165823-9096-4652-b131-09cce4464a8b] succeeded in 0.5091587560018525s: None
2022-05-19 16:57:33,040 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 16:57:33,044 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7dfbd0ef-aaff-4c63-a20f-7b9c9ad57899] received
2022-05-19 16:57:33,653 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7dfbd0ef-aaff-4c63-a20f-7b9c9ad57899] succeeded in 0.6075775429999339s: None
2022-05-19 17:02:33,051 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:02:33,054 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6192bd2d-8b71-487a-9423-e4b20b1acac1] received
2022-05-19 17:02:33,530 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6192bd2d-8b71-487a-9423-e4b20b1acac1] succeeded in 0.47393992200522916s: None
2022-05-19 17:07:33,061 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:07:33,064 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[15da94b1-3fe4-4b94-a2b5-d2b26be71bd2] received
2022-05-19 17:07:33,639 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[15da94b1-3fe4-4b94-a2b5-d2b26be71bd2] succeeded in 0.5733410559987533s: None
2022-05-19 17:12:33,067 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:12:33,069 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[12ee2d66-d97d-4536-a155-37c0f593cfb0] received
2022-05-19 17:12:33,648 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[12ee2d66-d97d-4536-a155-37c0f593cfb0] succeeded in 0.5774315899980138s: None
2022-05-19 17:17:33,078 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:17:33,081 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[111d67aa-b596-4c91-94ad-f92de59755d9] received
2022-05-19 17:17:33,577 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[111d67aa-b596-4c91-94ad-f92de59755d9] succeeded in 0.49386695999419317s: None
2022-05-19 17:22:33,089 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:22:33,094 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[45945b1e-589f-44cc-a7b7-46783f78b02f] received
2022-05-19 17:22:33,608 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[45945b1e-589f-44cc-a7b7-46783f78b02f] succeeded in 0.5128691289937706s: None
2022-05-19 17:27:33,096 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:27:33,098 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[87a31bd3-d78b-4ba6-b451-d4cb58436044] received
2022-05-19 17:27:33,647 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[87a31bd3-d78b-4ba6-b451-d4cb58436044] succeeded in 0.5474221609983942s: None
2022-05-19 17:32:33,107 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:32:33,109 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5471f756-3316-4e71-ad9a-e85a0f273345] received
2022-05-19 17:32:33,585 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5471f756-3316-4e71-ad9a-e85a0f273345] succeeded in 0.4738650650033378s: None
2022-05-19 17:37:33,119 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:37:33,122 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[44c5a7fc-18f7-4db8-af72-d31b19f6c23f] received
2022-05-19 17:37:33,614 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[44c5a7fc-18f7-4db8-af72-d31b19f6c23f] succeeded in 0.49028060200362233s: None
2022-05-19 17:42:33,130 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:42:33,135 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fb8b944a-5904-40ca-b199-60181dc770db] received
2022-05-19 17:42:33,636 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fb8b944a-5904-40ca-b199-60181dc770db] succeeded in 0.4993196750001516s: None
2022-05-19 17:47:33,141 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:47:33,144 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49922ef1-ae8a-40d0-afce-2d186ba12338] received
2022-05-19 17:47:33,793 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49922ef1-ae8a-40d0-afce-2d186ba12338] succeeded in 0.6474493889982114s: None
2022-05-19 17:52:33,148 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:52:33,150 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c50512d0-dd54-4058-b4aa-2b626483fd76] received
2022-05-19 17:52:33,597 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c50512d0-dd54-4058-b4aa-2b626483fd76] succeeded in 0.44517222300055437s: None
2022-05-19 17:57:33,155 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 17:57:33,157 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f2b94312-7996-4378-a455-efb68b092649] received
2022-05-19 17:57:33,661 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f2b94312-7996-4378-a455-efb68b092649] succeeded in 0.5026629620042513s: None
2022-05-19 18:02:33,164 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:02:33,166 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[88a91ff1-d3b1-477d-a56f-0c807cc65c34] received
2022-05-19 18:02:33,571 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[88a91ff1-d3b1-477d-a56f-0c807cc65c34] succeeded in 0.4025495400055661s: None
2022-05-19 18:07:33,176 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:07:33,178 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e236f21a-61e2-4074-9c03-1c99f964b361] received
2022-05-19 18:07:33,594 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e236f21a-61e2-4074-9c03-1c99f964b361] raised unexpected: TweepyException('503 Service Unavailable\n130 - Over capacity')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 45, in scrape_twitter
    statuses = api.home_timeline(count=200, tweet_mode='extended', since_id=last_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/tweepy/api.py", line 33, in wrapper
    return method(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/tweepy/api.py", line 46, in wrapper
    return method(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/tweepy/api.py", line 488, in home_timeline
    return self.request(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/tweepy/api.py", line 265, in request
    raise TwitterServerError(resp)
tweepy.errors.TweepyException: 503 Service Unavailable
130 - Over capacity
2022-05-19 18:12:33,185 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:12:33,187 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0cb2d3b4-edc9-4c00-9ea7-16fe99c2cd3e] received
2022-05-19 18:12:34,342 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0cb2d3b4-edc9-4c00-9ea7-16fe99c2cd3e] succeeded in 1.1531669899995904s: None
2022-05-19 18:17:33,195 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:17:33,197 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e3652503-a19e-4899-83a2-83f6e4019143] received
2022-05-19 18:17:33,679 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e3652503-a19e-4899-83a2-83f6e4019143] succeeded in 0.4799081809978816s: None
2022-05-19 18:22:33,201 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:22:33,203 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2de486d-805c-47be-90f9-28c3eab5883f] received
2022-05-19 18:22:33,734 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d2de486d-805c-47be-90f9-28c3eab5883f] succeeded in 0.528552450996358s: None
2022-05-19 18:27:33,209 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:27:33,212 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[36f6337e-9426-4c17-8943-ab8dea70def2] received
2022-05-19 18:27:38,702 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[36f6337e-9426-4c17-8943-ab8dea70def2] succeeded in 5.488351501997386s: None
2022-05-19 18:32:33,213 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:32:33,215 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6c4d983b-865a-4077-bab0-a843d4eceb0f] received
2022-05-19 18:32:33,623 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6c4d983b-865a-4077-bab0-a843d4eceb0f] succeeded in 0.40708258200174896s: None
2022-05-19 18:37:33,223 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:37:33,225 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[21686e5d-5f9e-4f9e-992d-c63c58a1bae2] received
2022-05-19 18:37:33,744 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[21686e5d-5f9e-4f9e-992d-c63c58a1bae2] succeeded in 0.5170124150026822s: None
2022-05-19 18:42:33,229 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:42:33,231 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a327d7b4-29ef-4d01-9de4-7194bd557528] received
2022-05-19 18:42:33,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a327d7b4-29ef-4d01-9de4-7194bd557528] succeeded in 0.43068627200409537s: None
2022-05-19 18:47:33,235 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:47:33,237 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2ed3e9ce-7440-4675-86a1-8db33e7d43f4] received
2022-05-19 18:47:33,699 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2ed3e9ce-7440-4675-86a1-8db33e7d43f4] succeeded in 0.4600352240013308s: None
2022-05-19 18:52:33,239 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:52:33,242 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[905b34e3-aefa-4915-9025-f9c6103fbfce] received
2022-05-19 18:52:33,636 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[905b34e3-aefa-4915-9025-f9c6103fbfce] succeeded in 0.393841272998543s: None
2022-05-19 18:57:33,246 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 18:57:33,248 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6585256d-5ec3-46d1-9e06-2cde2d5c7f21] received
2022-05-19 18:57:33,783 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6585256d-5ec3-46d1-9e06-2cde2d5c7f21] succeeded in 0.5327679520050879s: None
2022-05-19 19:02:33,246 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:02:33,248 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4d828e80-f6b5-421b-beaa-30e9d14b1144] received
2022-05-19 19:02:33,705 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4d828e80-f6b5-421b-beaa-30e9d14b1144] succeeded in 0.45572933399671456s: None
2022-05-19 19:07:33,247 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:07:33,250 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ede4db6-7d00-4e8a-953d-a7343de1104f] received
2022-05-19 19:07:33,866 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7ede4db6-7d00-4e8a-953d-a7343de1104f] succeeded in 0.6152018049979233s: None
2022-05-19 19:12:33,257 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:12:33,259 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0c2c3df7-357a-4bb8-a68d-38ff9eee0060] received
2022-05-19 19:12:33,796 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0c2c3df7-357a-4bb8-a68d-38ff9eee0060] succeeded in 0.5357937439985108s: None
2022-05-19 19:17:33,269 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:17:33,271 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8b9015eb-1a87-4354-802d-8c922370d704] received
2022-05-19 19:17:33,832 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8b9015eb-1a87-4354-802d-8c922370d704] succeeded in 0.559255657994072s: None
2022-05-19 19:22:33,280 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:22:33,282 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[19a182bc-9727-42a6-8baa-e93bb818568d] received
2022-05-19 19:22:33,759 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[19a182bc-9727-42a6-8baa-e93bb818568d] succeeded in 0.474955942001543s: None
2022-05-19 19:27:33,291 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:27:33,294 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2064805d-e5ed-4fe9-ba47-4f2e7f088aff] received
2022-05-19 19:27:33,797 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2064805d-e5ed-4fe9-ba47-4f2e7f088aff] succeeded in 0.5020754349970957s: None
2022-05-19 19:32:33,302 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:32:33,305 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e6fc4e3e-5610-49ec-b2e5-bba686d9cca0] received
2022-05-19 19:32:33,847 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e6fc4e3e-5610-49ec-b2e5-bba686d9cca0] succeeded in 0.5401638179973816s: None
2022-05-19 19:37:33,313 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:37:33,316 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c43b83c6-297b-4309-9f13-12902c19048d] received
2022-05-19 19:37:33,836 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c43b83c6-297b-4309-9f13-12902c19048d] succeeded in 0.518681891997403s: None
2022-05-19 19:42:33,322 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:42:33,324 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[019cf51b-ff74-4f6b-b6a7-2ca741d7c4e4] received
2022-05-19 19:42:33,817 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[019cf51b-ff74-4f6b-b6a7-2ca741d7c4e4] succeeded in 0.4922351740024169s: None
2022-05-19 19:47:33,332 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:47:33,335 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[317834d2-ab2e-478d-8e6b-9395ecccf1a9] received
2022-05-19 19:47:33,830 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[317834d2-ab2e-478d-8e6b-9395ecccf1a9] succeeded in 0.49368116300320253s: None
2022-05-19 19:52:33,343 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:52:33,346 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ffbedcc8-d524-4efe-b0d3-618b0fad57c6] received
2022-05-19 19:52:33,889 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ffbedcc8-d524-4efe-b0d3-618b0fad57c6] succeeded in 0.5417231000028551s: None
2022-05-19 19:57:33,354 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 19:57:33,356 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[73359dd6-66bf-4161-a4bd-d444a849e053] received
2022-05-19 19:57:33,912 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[73359dd6-66bf-4161-a4bd-d444a849e053] succeeded in 0.5542048350034747s: None
2022-05-19 20:02:33,364 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:02:33,367 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2a0597c4-3236-447d-b86d-846bffe3c6d7] received
2022-05-19 20:02:33,838 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2a0597c4-3236-447d-b86d-846bffe3c6d7] succeeded in 0.469252005997987s: None
2022-05-19 20:07:33,375 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:07:33,377 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[334608f4-7243-41bb-be43-33a7c95e7575] received
2022-05-19 20:07:33,931 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[334608f4-7243-41bb-be43-33a7c95e7575] succeeded in 0.5519796509979642s: None
2022-05-19 20:12:33,385 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:12:33,387 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1aa14ccc-47d3-41f4-891b-7e628329df5f] received
2022-05-19 20:12:33,916 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1aa14ccc-47d3-41f4-891b-7e628329df5f] succeeded in 0.5272970910009462s: None
2022-05-19 20:17:33,396 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:17:33,398 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b86fec41-0c18-43bb-88a6-ce7a24e76b2e] received
2022-05-19 20:17:33,958 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b86fec41-0c18-43bb-88a6-ce7a24e76b2e] succeeded in 0.5581823339962284s: None
2022-05-19 20:22:33,407 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:22:33,410 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6736840e-cea1-4898-a1ef-991f3d797438] received
2022-05-19 20:22:33,986 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6736840e-cea1-4898-a1ef-991f3d797438] succeeded in 0.5745790979999583s: None
2022-05-19 20:27:33,418 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:27:33,421 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1117f9e0-a6ee-4d5d-8a98-91ffe4352bad] received
2022-05-19 20:27:34,023 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1117f9e0-a6ee-4d5d-8a98-91ffe4352bad] succeeded in 0.6007556389959063s: None
2022-05-19 20:32:33,426 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:32:33,429 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0695a91-2a12-46ab-a97f-9f4c2755fe1f] received
2022-05-19 20:32:33,862 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0695a91-2a12-46ab-a97f-9f4c2755fe1f] succeeded in 0.43219844499981264s: None
2022-05-19 20:37:33,437 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:37:33,439 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[78db0069-dac2-4131-a4a8-28ddfddae4c9] received
2022-05-19 20:37:33,885 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[78db0069-dac2-4131-a4a8-28ddfddae4c9] succeeded in 0.4444883479955024s: None
2022-05-19 20:42:33,447 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:42:33,449 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5541fc82-e7a8-440c-9cf9-a021855a6222] received
2022-05-19 20:42:33,958 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5541fc82-e7a8-440c-9cf9-a021855a6222] succeeded in 0.5067784950006171s: None
2022-05-19 20:47:33,457 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:47:33,460 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7578e7b7-dd91-4acc-b660-dd7e111bc3a0] received
2022-05-19 20:47:33,955 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7578e7b7-dd91-4acc-b660-dd7e111bc3a0] succeeded in 0.4934019740030635s: None
2022-05-19 20:52:33,466 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:52:33,468 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e80e07f-6101-4384-a5ca-549616d348ff] received
2022-05-19 20:52:34,008 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e80e07f-6101-4384-a5ca-549616d348ff] succeeded in 0.5391061089976574s: None
2022-05-19 20:57:33,477 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 20:57:33,479 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c122c51b-0aef-4b06-8ab4-10486f9899db] received
2022-05-19 20:57:33,939 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c122c51b-0aef-4b06-8ab4-10486f9899db] succeeded in 0.45909437500085915s: None
2022-05-19 21:02:33,486 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:02:33,488 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a7541de5-ab52-4d9b-9403-a56671ab3dae] received
2022-05-19 21:02:33,979 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a7541de5-ab52-4d9b-9403-a56671ab3dae] succeeded in 0.48999774800176965s: None
2022-05-19 21:07:33,488 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:07:33,490 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8215fee7-9ecc-46c9-a0f2-4fa4c62d06dd] received
2022-05-19 21:07:33,999 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8215fee7-9ecc-46c9-a0f2-4fa4c62d06dd] succeeded in 0.507400320006127s: None
2022-05-19 21:12:33,500 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:12:33,502 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[42a0b62b-8905-412b-9a30-c0d109acb8ff] received
2022-05-19 21:12:34,014 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[42a0b62b-8905-412b-9a30-c0d109acb8ff] succeeded in 0.5096389509999426s: None
2022-05-19 21:17:33,511 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:17:33,513 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[df339c83-e059-42cf-90b5-f878bee933fb] received
2022-05-19 21:17:34,228 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[df339c83-e059-42cf-90b5-f878bee933fb] succeeded in 0.7126007860060781s: None
2022-05-19 21:22:33,521 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:22:33,523 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b03fcbe8-3f46-4af4-aefd-d46b8bd21b05] received
2022-05-19 21:22:33,993 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b03fcbe8-3f46-4af4-aefd-d46b8bd21b05] succeeded in 0.469315889000427s: None
2022-05-19 21:27:33,532 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:27:33,534 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[affcaf00-42ff-45ec-994e-3a8295f5bae5] received
2022-05-19 21:27:34,033 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[affcaf00-42ff-45ec-994e-3a8295f5bae5] succeeded in 0.4966133749985602s: None
2022-05-19 21:32:33,543 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:32:33,546 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9e82ef53-d3ee-4016-b2fd-146b672e375e] received
2022-05-19 21:32:33,967 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9e82ef53-d3ee-4016-b2fd-146b672e375e] succeeded in 0.42018281600030605s: None
2022-05-19 21:37:33,555 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:37:33,557 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8646a2fc-9ff6-4971-88ec-5adc95898617] received
2022-05-19 21:37:33,966 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8646a2fc-9ff6-4971-88ec-5adc95898617] succeeded in 0.40736561399535276s: None
2022-05-19 21:42:33,562 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:42:33,565 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8da65a0c-3882-4d99-b1c4-272161b81216] received
2022-05-19 21:42:34,024 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8da65a0c-3882-4d99-b1c4-272161b81216] succeeded in 0.45784738400107017s: None
2022-05-19 21:47:33,570 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:47:33,572 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[70d64235-e3c0-46ef-91cb-2ee7eb6d4f2e] received
2022-05-19 21:47:34,099 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[70d64235-e3c0-46ef-91cb-2ee7eb6d4f2e] succeeded in 0.5256005599949276s: None
2022-05-19 21:52:33,581 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:52:33,584 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[38b34eb5-41ef-470f-8f6d-216e256f48a0] received
2022-05-19 21:52:34,364 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[38b34eb5-41ef-470f-8f6d-216e256f48a0] succeeded in 0.7780158820023644s: None
2022-05-19 21:57:33,587 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 21:57:33,589 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1ea1709c-c9f7-4b03-808e-ad0a17deb5a1] received
2022-05-19 21:57:34,178 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1ea1709c-c9f7-4b03-808e-ad0a17deb5a1] succeeded in 0.5882163909991505s: None
2022-05-19 22:02:33,594 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:02:33,596 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5e1b32a1-594d-4832-abef-a3102c01ff41] received
2022-05-19 22:02:34,081 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5e1b32a1-594d-4832-abef-a3102c01ff41] succeeded in 0.48330912600067677s: None
2022-05-19 22:07:33,597 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:07:33,599 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3441c5af-4207-499f-b745-3dc3ba3b6e65] received
2022-05-19 22:07:34,019 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3441c5af-4207-499f-b745-3dc3ba3b6e65] succeeded in 0.4180346489956719s: None
2022-05-19 22:12:33,608 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:12:33,611 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1d6a1f21-3f16-42f8-942c-a2df542d0e00] received
2022-05-19 22:12:34,078 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1d6a1f21-3f16-42f8-942c-a2df542d0e00] succeeded in 0.4651848930006963s: None
2022-05-19 22:17:33,611 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:17:33,613 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[068cfe6f-7044-4868-a06f-a710db6fde2e] received
2022-05-19 22:17:34,108 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[068cfe6f-7044-4868-a06f-a710db6fde2e] succeeded in 0.4939434319967404s: None
2022-05-19 22:22:33,618 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:22:33,621 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[486707ea-e74d-45cd-a0f7-b24bc5853d5a] received
2022-05-19 22:22:34,138 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[486707ea-e74d-45cd-a0f7-b24bc5853d5a] succeeded in 0.5157776499981992s: None
2022-05-19 22:27:33,630 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:27:33,632 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a43d4fd9-2cc4-4ec3-b6bb-b6fdbf4dfec5] received
2022-05-19 22:27:34,058 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a43d4fd9-2cc4-4ec3-b6bb-b6fdbf4dfec5] succeeded in 0.42475151699909475s: None
2022-05-19 22:32:33,642 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:32:33,644 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[499c12e5-f304-4011-b09a-2b4c0bebbc3d] received
2022-05-19 22:32:34,205 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[499c12e5-f304-4011-b09a-2b4c0bebbc3d] succeeded in 0.559145917002752s: None
2022-05-19 22:37:33,653 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:37:33,655 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4837ac4a-900f-47bb-9ffe-4c0b9060c874] received
2022-05-19 22:37:34,177 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4837ac4a-900f-47bb-9ffe-4c0b9060c874] succeeded in 0.5199552569974912s: None
2022-05-19 22:42:33,663 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 22:42:33,665 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4216373d-2d04-402d-bb04-9b5581b6d856] received
2022-05-19 22:42:34,171 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4216373d-2d04-402d-bb04-9b5581b6d856] succeeded in 0.5037224869956844s: None
2022-05-20 05:49:11,059 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-20 05:49:11,564 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-20 05:49:11,567 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-20 05:49:11,573 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-20 05:49:12,583 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-20 05:49:12,603 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-20 05:49:12,603 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-20 05:49:20,646 - celery.beat - INFO - beat: Starting...
2022-05-20 05:49:20,719 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 05:49:20,734 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0a5d6ac8-2dc2-4d1e-a11a-0b56973898b8] received
2022-05-20 05:49:22,286 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-20 05:49:22,448 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0a5d6ac8-2dc2-4d1e-a11a-0b56973898b8] succeeded in 1.7131016769999974s: None
2022-05-20 05:54:20,727 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 05:54:20,730 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6c84927e-3cb7-466a-92e2-50149bad8612] received
2022-05-20 05:54:21,544 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6c84927e-3cb7-466a-92e2-50149bad8612] succeeded in 0.8123197110001001s: None
2022-05-20 05:59:20,739 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 05:59:20,742 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[819f85c2-11f7-44c7-8954-c9ebf46eb276] received
2022-05-20 05:59:21,139 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[819f85c2-11f7-44c7-8954-c9ebf46eb276] succeeded in 0.3955599199999824s: None
2022-05-20 06:04:20,750 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:04:20,752 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e2625abb-9680-4341-8528-3d795e71bfbe] received
2022-05-20 06:04:21,185 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e2625abb-9680-4341-8528-3d795e71bfbe] succeeded in 0.4320473289999427s: None
2022-05-20 06:09:20,761 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:09:20,763 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cb10883f-a44d-4294-b546-9083e935dc45] received
2022-05-20 06:09:21,243 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cb10883f-a44d-4294-b546-9083e935dc45] succeeded in 0.4787551889999122s: None
2022-05-20 06:14:20,771 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:14:20,774 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0a3cb4b8-bdc2-4c2d-9c76-abbe7d436fe2] received
2022-05-20 06:14:21,161 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0a3cb4b8-bdc2-4c2d-9c76-abbe7d436fe2] succeeded in 0.3851611140000841s: None
2022-05-20 06:19:20,782 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:19:20,784 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1b1120c1-f5c8-4c3a-bf3a-1eaaaa9d47c0] received
2022-05-20 06:19:21,301 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1b1120c1-f5c8-4c3a-bf3a-1eaaaa9d47c0] succeeded in 0.5153985540000576s: None
2022-05-20 06:24:20,791 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:24:20,793 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7aaf2715-0bb6-4922-a5b7-16d0d287c556] received
2022-05-20 06:24:21,230 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7aaf2715-0bb6-4922-a5b7-16d0d287c556] succeeded in 0.43646967199993014s: None
2022-05-20 06:29:20,801 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:29:20,803 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c7c67c4f-376e-4a43-a0ba-29ce48d2f76a] received
2022-05-20 06:29:21,265 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c7c67c4f-376e-4a43-a0ba-29ce48d2f76a] succeeded in 0.4599663399999372s: None
2022-05-20 06:34:20,809 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:34:20,812 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eea387c3-168d-47f3-89ab-5079dd403041] received
2022-05-20 06:34:21,322 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eea387c3-168d-47f3-89ab-5079dd403041] succeeded in 0.5083040029999211s: None
2022-05-20 06:39:20,820 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:39:20,823 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9c2dbec2-b0aa-41b3-8b94-2d486216ee8d] received
2022-05-20 06:39:21,134 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9c2dbec2-b0aa-41b3-8b94-2d486216ee8d] succeeded in 0.3110585350000292s: None
2022-05-20 06:44:20,832 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:44:20,834 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[75b3f73f-9798-41cf-9b81-d50f2ba63011] received
2022-05-20 06:44:21,270 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[75b3f73f-9798-41cf-9b81-d50f2ba63011] succeeded in 0.4341783539998687s: None
2022-05-20 06:49:20,844 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:49:20,846 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8bd6b6f1-81c3-4a43-b364-efcd0602594f] received
2022-05-20 06:49:21,215 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8bd6b6f1-81c3-4a43-b364-efcd0602594f] succeeded in 0.3676455410000017s: None
2022-05-20 06:54:20,851 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:54:20,852 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[797978fb-c645-47dd-a5f0-f016934ad3a1] received
2022-05-20 06:54:21,250 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[797978fb-c645-47dd-a5f0-f016934ad3a1] succeeded in 0.3964599239998279s: None
2022-05-20 06:59:20,855 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 06:59:20,857 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[934a2438-2e7d-4212-ae1a-784acb18395c] received
2022-05-20 06:59:21,281 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[934a2438-2e7d-4212-ae1a-784acb18395c] succeeded in 0.42220203899978515s: None
2022-05-20 07:04:20,867 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:04:20,870 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[17c82264-29a3-4d41-b9d9-1941a3f5db79] received
2022-05-20 07:04:21,326 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[17c82264-29a3-4d41-b9d9-1941a3f5db79] succeeded in 0.45471628500035877s: None
2022-05-20 07:09:20,878 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:09:20,881 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b824acf-4dd0-4b5b-8fb6-ed5516742207] received
2022-05-20 07:09:21,257 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b824acf-4dd0-4b5b-8fb6-ed5516742207] succeeded in 0.37465702000008605s: None
2022-05-20 07:14:20,881 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:14:20,883 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[449b113d-6b8b-4afd-8891-d0ec1e76df4d] received
2022-05-20 07:14:21,354 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[449b113d-6b8b-4afd-8891-d0ec1e76df4d] succeeded in 0.46936041500066494s: None
2022-05-20 07:19:20,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:19:20,892 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9f0cbcd7-a23e-4545-ba8a-97fc90137326] received
2022-05-20 07:19:21,447 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9f0cbcd7-a23e-4545-ba8a-97fc90137326] succeeded in 0.5540794489998007s: None
2022-05-20 07:24:20,897 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:24:20,899 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[63c64ee5-a68b-46cc-b622-551477391c3b] received
2022-05-20 07:24:21,288 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[63c64ee5-a68b-46cc-b622-551477391c3b] succeeded in 0.3872705710000446s: None
2022-05-20 07:29:20,901 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:29:20,902 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fc08b775-ed59-4c74-b1a0-3520b5a09484] received
2022-05-20 07:29:21,496 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fc08b775-ed59-4c74-b1a0-3520b5a09484] succeeded in 0.5926101669992931s: None
2022-05-20 07:34:20,911 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:34:20,913 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[69602380-01ee-4896-8df1-06c23b6daab6] received
2022-05-20 07:34:21,334 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[69602380-01ee-4896-8df1-06c23b6daab6] succeeded in 0.4198389279999901s: None
2022-05-20 07:39:20,917 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:39:20,919 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b58eb4e-98a0-4d7a-947f-c18fde7bc70d] received
2022-05-20 07:39:21,244 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b58eb4e-98a0-4d7a-947f-c18fde7bc70d] succeeded in 0.32374196100045083s: None
2022-05-20 07:44:20,925 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:44:20,927 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7a9281f8-25d9-42b5-9255-f2f80fd95ba5] received
2022-05-20 07:44:21,302 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7a9281f8-25d9-42b5-9255-f2f80fd95ba5] succeeded in 0.37458969599993s: None
2022-05-20 07:49:20,935 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:49:20,938 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e1e89ba7-0a26-4d79-b8bd-1ef3b9f6b622] received
2022-05-20 07:49:21,261 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e1e89ba7-0a26-4d79-b8bd-1ef3b9f6b622] succeeded in 0.3207039529997928s: None
2022-05-20 07:54:20,946 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:54:20,948 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2431ea2d-9c9b-405b-ba8c-46c21bdfb78e] received
2022-05-20 07:54:21,352 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2431ea2d-9c9b-405b-ba8c-46c21bdfb78e] succeeded in 0.40180168700044305s: None
2022-05-20 07:59:20,948 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 07:59:20,951 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7512533b-9978-4280-a86d-c6a6b1aed22a] received
2022-05-20 07:59:21,328 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7512533b-9978-4280-a86d-c6a6b1aed22a] succeeded in 0.3758889900000213s: None
2022-05-20 08:04:20,960 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:04:20,962 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e879214f-8b65-4701-a8e1-392f0cafad41] received
2022-05-20 08:04:21,411 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e879214f-8b65-4701-a8e1-392f0cafad41] succeeded in 0.44761319900135277s: None
2022-05-20 08:09:20,970 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:09:20,972 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4aded3bc-afb3-425f-bdc2-e49e300dbc05] received
2022-05-20 08:09:21,400 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4aded3bc-afb3-425f-bdc2-e49e300dbc05] succeeded in 0.4259473269994487s: None
2022-05-20 08:14:20,977 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:14:20,979 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[86f30a4e-cb2d-4ae5-806d-058470c2737c] received
2022-05-20 08:14:21,625 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[86f30a4e-cb2d-4ae5-806d-058470c2737c] succeeded in 0.6443502340007399s: None
2022-05-20 08:19:20,987 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:19:20,990 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3437b5c2-cf9d-4e13-b7de-0c942e81e5fb] received
2022-05-20 08:19:21,446 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3437b5c2-cf9d-4e13-b7de-0c942e81e5fb] succeeded in 0.45462456899986137s: None
2022-05-20 08:24:20,995 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:24:20,997 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49f38997-3949-4afc-8811-145e29909ae4] received
2022-05-20 08:24:21,372 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49f38997-3949-4afc-8811-145e29909ae4] succeeded in 0.37231864999921527s: None
2022-05-20 08:29:21,005 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:29:21,008 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f4c66039-e169-46eb-9c31-5a0e326aef8e] received
2022-05-20 08:29:21,651 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f4c66039-e169-46eb-9c31-5a0e326aef8e] succeeded in 0.6414081460006855s: None
2022-05-20 08:34:21,015 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:34:21,018 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d1567f0f-3fe6-49ba-b189-01f3218797cf] received
2022-05-20 08:34:21,453 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d1567f0f-3fe6-49ba-b189-01f3218797cf] succeeded in 0.4343739360010659s: None
2022-05-20 08:39:21,026 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:39:21,028 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[29e1de48-1de8-4f31-83e5-3808dbe71250] received
2022-05-20 08:39:21,485 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[29e1de48-1de8-4f31-83e5-3808dbe71250] succeeded in 0.4545530230006989s: None
2022-05-20 08:44:21,034 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:44:21,036 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[392e7246-1014-467a-9e8c-3844f2c78862] received
2022-05-20 08:44:21,415 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[392e7246-1014-467a-9e8c-3844f2c78862] succeeded in 0.37742814699959126s: None
2022-05-20 08:49:21,044 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:49:21,046 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e19a97b6-4698-4962-8f6d-d338996fe6e9] received
2022-05-20 08:49:21,452 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e19a97b6-4698-4962-8f6d-d338996fe6e9] succeeded in 0.40383674599979713s: None
2022-05-20 08:54:21,053 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:54:21,056 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c5099639-cf91-40b7-ae87-304663a113d8] received
2022-05-20 08:54:21,479 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c5099639-cf91-40b7-ae87-304663a113d8] succeeded in 0.42189838999911444s: None
2022-05-20 08:59:21,055 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 08:59:21,057 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c474ce31-64b7-44f8-b748-099f7e630e38] received
2022-05-20 08:59:21,342 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c474ce31-64b7-44f8-b748-099f7e630e38] succeeded in 0.2838855709997006s: None
2022-05-20 09:04:21,066 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:04:21,069 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[07bc3db1-d8c2-49ed-bc30-c74c868207a7] received
2022-05-20 09:04:21,896 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[07bc3db1-d8c2-49ed-bc30-c74c868207a7] succeeded in 0.8256608730007429s: None
2022-05-20 09:09:21,070 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:09:21,072 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4629385b-f7fd-4562-bb0b-0194eb510a57] received
2022-05-20 09:09:21,586 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4629385b-f7fd-4562-bb0b-0194eb510a57] succeeded in 0.5120387530005246s: None
2022-05-20 09:14:21,080 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:14:21,083 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[26f1fe90-a023-4628-b20b-2e280cf2f185] received
2022-05-20 09:14:21,534 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[26f1fe90-a023-4628-b20b-2e280cf2f185] succeeded in 0.4494294229989464s: None
2022-05-20 09:19:21,087 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:19:21,089 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9dd6fcc9-5c09-4823-8d63-a2699562be99] received
2022-05-20 09:19:21,563 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9dd6fcc9-5c09-4823-8d63-a2699562be99] succeeded in 0.4724730380003166s: None
2022-05-20 09:24:21,094 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:24:21,096 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f0da9d95-086b-48d2-aa62-f325543d7713] received
2022-05-20 09:24:21,508 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f0da9d95-086b-48d2-aa62-f325543d7713] succeeded in 0.4109035509991372s: None
2022-05-20 09:29:21,095 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:29:21,097 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ebc13d2e-966c-43c5-9413-2aa9049d3e88] received
2022-05-20 09:29:21,831 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ebc13d2e-966c-43c5-9413-2aa9049d3e88] succeeded in 0.7324554219994752s: None
2022-05-20 09:34:21,097 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:34:21,099 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[14dfe8d3-1edc-4157-b862-0e3f4a89a7dd] received
2022-05-20 09:34:21,555 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[14dfe8d3-1edc-4157-b862-0e3f4a89a7dd] succeeded in 0.4534289670009457s: None
2022-05-20 09:39:21,101 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:39:21,104 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[309479c9-d3e3-44de-9021-c94abeee07a1] received
2022-05-20 09:39:21,517 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[309479c9-d3e3-44de-9021-c94abeee07a1] succeeded in 0.4123373980000906s: None
2022-05-20 09:44:21,105 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-20 09:44:21,107 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[af38950c-ef13-4e62-9e37-93fdb171802f] received
2022-05-20 09:44:21,620 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[af38950c-ef13-4e62-9e37-93fdb171802f] succeeded in 0.5117251640003815s: None
