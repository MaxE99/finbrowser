2022-05-14 10:45:20,900 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 10:45:20,916 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] received
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 2022-05-14 02:53:09+00:00
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 20220514-025309
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 2022-05-14 02:52:36+00:00
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 20220514-025236
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 2022-05-14 02:52:08+00:00
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 20220514-025208
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 2022-05-14 02:48:38+00:00
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 20220514-024838
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - 2022-05-14 02:47:50+00:00
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - 20220514-024750
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 2022-05-13 23:47:38+00:00
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 20220513-234738
2022-05-14 10:45:22,161 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 2022-05-13 21:06:15+00:00
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 20220513-210615
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 2022-05-13 20:16:48+00:00
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 20220513-201648
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - 2022-05-13 18:01:09+00:00
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - 20220513-180109
2022-05-14 10:45:22,186 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 2022-05-13 16:31:18+00:00
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 20220513-163118
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 2022-05-13 16:20:49+00:00
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 20220513-162049
2022-05-14 10:45:22,218 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] succeeded in 1.3010347979979997s: None
2022-05-14 11:00:20,904 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:00:20,907 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] received
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:00:21,743 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:15:20,912 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:15:20,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] received
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:15:21,742 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:15:21,745 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:30:20,919 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:30:20,921 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] received
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:30:21,772 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:44:25,559 - celery.beat - INFO - beat: Starting...
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Exception ignored in atexit callback
2022-05-14 11:44:29,751 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,751 - celery.redirected - WARNING - <function _exit_function at 0x7f45a0622d40>
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Traceback (most recent call last):
2022-05-14 11:44:29,751 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 334, in _exit_function
2022-05-14 11:44:29,754 - celery.redirected - WARNING -     
2022-05-14 11:44:29,754 - celery.redirected - WARNING - _run_finalizers(0)
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
2022-05-14 11:44:29,755 - celery.redirected - WARNING -     
2022-05-14 11:44:29,755 - celery.redirected - WARNING - finalizer()
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
2022-05-14 11:44:29,756 - celery.redirected - WARNING -     
2022-05-14 11:44:29,756 - celery.redirected - WARNING - res = self._callback(*self._args, **self._kwargs)
2022-05-14 11:44:29,756 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/billiard/pool.py", line 1662, in _terminate_pool
2022-05-14 11:44:29,757 - celery.redirected - WARNING -     
2022-05-14 11:44:29,758 - celery.redirected - WARNING - cls._help_stuff_finish(*help_stuff_finish_args)
2022-05-14 11:44:29,758 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 1341, in _help_stuff_finish
2022-05-14 11:44:29,759 - celery.redirected - WARNING -     
2022-05-14 11:44:29,759 - celery.redirected - WARNING - readable, _, again = _select(inqR, timeout=0.5)
2022-05-14 11:44:29,759 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 165, in _select
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,760 - celery.redirected - WARNING - return poll(readers, writers, err, timeout)
2022-05-14 11:44:29,760 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 121, in _select_imp
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,761 - celery.redirected - WARNING - events = poller.poll(timeout)
2022-05-14 11:44:29,761 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/apps/worker.py", line 299, in _handle_request
2022-05-14 11:44:29,761 - celery.redirected - WARNING -     
2022-05-14 11:44:29,762 - celery.redirected - WARNING - raise exc(exitcode)
2022-05-14 11:44:29,762 - celery.redirected - WARNING - celery.exceptions
2022-05-14 11:44:29,762 - celery.redirected - WARNING - .
2022-05-14 11:44:29,762 - celery.redirected - WARNING - WorkerTerminate
2022-05-14 11:44:29,762 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,763 - celery.redirected - WARNING - 1
2022-05-14 11:44:31,843 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:32,393 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 11:44:32,396 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 11:44:32,401 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:33,413 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 11:44:33,438 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 11:44:33,438 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 11:44:35,042 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:15:20,941 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:15:20,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] received
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 2022-05-14 12:15:10+00:00
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'float'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 1652530510.0
2022-05-14 12:15:21,757 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] raised unexpected: TypeError('expected string or bytes-like object')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    cache.set('last_id', last_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1367, in to_python
    parsed = parse_datetime(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/utils/dateparse.py", line 107, in parse_datetime
    match = datetime_re.match(value)
TypeError: expected string or bytes-like object
2022-05-14 12:17:57,522 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:58,032 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:17:58,038 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:17:58,044 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:59,055 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:17:59,075 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:17:59,075 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:18:16,642 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:18:26,059 - celery.beat - INFO - beat: Starting...
2022-05-14 12:18:26,144 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:18:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] received
2022-05-14 12:18:26,962 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,966 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,975 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,981 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,987 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,993 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,999 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,005 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,011 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,020 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,026 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,032 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,038 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,044 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,050 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,052 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,055 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,086 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,094 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,125 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,141 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,193 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,251 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] succeeded in 1.0985599829982675s: None
2022-05-14 12:33:26,149 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:33:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] received
2022-05-14 12:33:27,054 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,067 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,069 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,095 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,104 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,107 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,134 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,183 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,208 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,214 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,269 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] succeeded in 1.1157525369999348s: None
2022-05-14 12:37:40,583 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:41,124 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:37:41,127 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:37:41,131 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:42,140 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:37:42,153 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:37:42,153 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:37:55,496 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:38:01,602 - celery.beat - INFO - beat: Starting...
2022-05-14 12:48:26,166 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:48:26,181 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] received
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - 2022-05-14 12:48:07+00:00
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 12:48:27,082 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] raised unexpected: ValidationError(['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 12:57:17,676 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:18,242 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:57:18,245 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:57:18,249 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:19,259 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:57:19,269 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:57:19,269 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:57:28,245 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:57:29,701 - celery.beat - INFO - beat: Starting...
2022-05-14 13:03:26,167 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:03:26,184 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] received
2022-05-14 13:03:27,079 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,090 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,114 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,155 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,180 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,203 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,225 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,232 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,234 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,257 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] succeeded in 1.071642716997303s: None
2022-05-14 13:18:26,172 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:18:26,175 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] received
2022-05-14 13:18:27,063 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,070 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,072 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,084 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,085 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,087 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,105 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,124 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,150 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] succeeded in 0.9730412339995382s: None
2022-05-15 06:03:29,186 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:29,708 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-15 06:03:29,712 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-15 06:03:29,726 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:30,739 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-15 06:03:30,759 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-15 06:03:30,760 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-15 06:03:59,089 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-15 06:04:19,529 - celery.beat - INFO - beat: Starting...
2022-05-15 06:04:19,604 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:04:19,611 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] received
2022-05-15 06:04:21,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] succeeded in 1.4147976009999752s: None
2022-05-15 06:19:19,609 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:19:19,612 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] received
2022-05-15 06:19:20,640 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] succeeded in 1.026817458000096s: None
2022-05-15 06:34:19,613 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:34:19,615 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] received
2022-05-15 06:34:21,305 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] succeeded in 1.6879922109997096s: None
2022-05-15 06:49:19,621 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:49:19,624 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] received
2022-05-15 06:49:20,681 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] succeeded in 1.0558503859997472s: None
2022-05-15 07:04:19,629 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:04:19,631 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] received
2022-05-15 07:04:20,602 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] succeeded in 0.9688271340000938s: None
2022-05-15 07:19:19,636 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:19:19,639 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] received
2022-05-15 07:19:20,583 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] succeeded in 0.9425648280002861s: None
2022-05-15 07:34:19,645 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:34:19,647 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] received
2022-05-15 07:34:20,651 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] succeeded in 1.0023042969996823s: None
2022-05-15 07:49:19,650 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:49:19,652 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] received
2022-05-15 07:49:25,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] succeeded in 6.01083675100017s: None
2022-05-15 08:04:19,651 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:04:19,653 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] received
2022-05-15 08:04:20,689 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] succeeded in 1.0345966639997641s: None
2022-05-15 08:19:19,654 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:19:19,656 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] received
2022-05-15 08:19:20,596 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] succeeded in 0.9384977319987229s: None
2022-05-15 08:34:19,660 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:34:19,663 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] received
2022-05-15 08:34:20,747 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] succeeded in 1.0831241819996649s: None
2022-05-15 08:49:19,668 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:49:19,671 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] received
2022-05-15 08:49:20,734 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] succeeded in 1.0619436870001664s: None
2022-05-15 09:04:19,677 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:04:19,679 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] received
2022-05-15 09:04:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] succeeded in 1.0476529040006426s: None
2022-05-15 09:19:19,684 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:19:19,686 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] received
2022-05-15 09:19:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] succeeded in 1.0407590319991868s: None
2022-05-15 09:34:19,689 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:34:19,690 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] received
2022-05-15 09:34:20,793 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] succeeded in 1.1009754080005223s: None
2022-05-15 09:49:19,698 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:49:19,700 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] received
2022-05-15 09:49:20,824 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] succeeded in 1.1221691869995993s: None
2022-05-15 10:04:19,707 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:04:19,709 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] received
2022-05-15 10:04:20,620 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] succeeded in 0.9095417999997153s: None
2022-05-15 10:19:19,714 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:19:19,715 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] received
2022-05-15 10:19:20,752 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] succeeded in 1.0352385839996714s: None
2022-05-15 10:34:19,718 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:34:19,721 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] received
2022-05-15 10:34:32,181 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] succeeded in 12.45846082800199s: None
2022-05-15 10:49:19,725 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:49:19,729 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] received
2022-05-15 10:49:20,735 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] succeeded in 1.004684849998739s: None
2022-05-15 11:04:19,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:04:19,736 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] received
2022-05-15 11:04:20,698 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] succeeded in 0.9611234969997895s: None
2022-05-15 11:19:19,741 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:19:19,744 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] received
2022-05-15 11:19:20,751 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] succeeded in 1.005611074000626s: None
2022-05-15 11:34:19,743 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:34:19,745 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] received
2022-05-15 11:34:20,827 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] succeeded in 1.079889598000591s: None
2022-05-15 11:49:19,751 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:49:19,754 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] received
2022-05-15 11:49:20,799 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] succeeded in 1.0442504599996028s: None
2022-05-15 12:04:19,760 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:04:19,762 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] received
2022-05-15 12:04:20,807 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] succeeded in 1.0433865410013823s: None
2022-05-15 12:19:19,768 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:19:19,771 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] received
2022-05-15 12:19:20,846 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] succeeded in 1.0730322370000067s: None
2022-05-15 12:34:19,776 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:34:19,779 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] received
2022-05-15 12:34:20,870 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] succeeded in 1.0889358870008436s: None
2022-05-15 12:49:19,784 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:49:19,786 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] received
2022-05-15 12:49:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] succeeded in 1.0519879430030414s: None
2022-05-15 13:04:19,791 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:04:19,793 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] received
2022-05-15 13:04:20,856 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] succeeded in 1.0612804999982473s: None
2022-05-15 13:19:19,798 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:19:19,800 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] received
2022-05-15 13:19:20,847 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] succeeded in 1.0460207639989676s: None
2022-05-15 13:34:19,804 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:34:19,806 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] received
2022-05-15 13:34:20,905 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] succeeded in 1.09683028499785s: None
2022-05-15 13:49:19,813 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:49:19,816 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] received
2022-05-15 13:49:20,842 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] succeeded in 1.0248260299995309s: None
2022-05-15 14:04:19,822 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:04:19,825 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] received
2022-05-15 14:04:20,918 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] succeeded in 1.092042811000283s: None
2022-05-15 14:19:19,830 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:19:19,832 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] received
2022-05-15 14:19:20,930 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] succeeded in 1.096971050999855s: None
2022-05-15 14:34:19,838 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:34:19,841 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] received
2022-05-15 14:34:20,946 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] succeeded in 1.1038280469983874s: None
2022-05-15 14:49:19,848 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:49:19,852 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] received
2022-05-15 14:49:20,955 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] succeeded in 1.1017984110003454s: None
2022-05-15 15:04:19,849 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:04:19,850 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] received
2022-05-15 15:04:20,844 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] succeeded in 0.9928378679978778s: None
2022-05-15 15:19:19,857 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:19:19,859 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] received
2022-05-15 15:19:21,020 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] succeeded in 1.1604612469964195s: None
2022-05-15 15:34:19,865 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:34:19,869 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] received
2022-05-15 15:34:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] succeeded in 1.1178659559955122s: None
2022-05-15 15:49:19,873 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:49:19,876 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] received
2022-05-15 15:49:21,089 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] succeeded in 1.2116717239987338s: None
2022-05-15 16:04:19,881 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:04:19,884 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] received
2022-05-15 16:04:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] succeeded in 0.955031568002596s: None
2022-05-15 16:19:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:19:19,891 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] received
2022-05-15 16:19:20,974 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] succeeded in 1.0816527050046716s: None
2022-05-15 16:34:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:34:19,890 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] received
2022-05-15 16:34:20,976 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] succeeded in 1.084029563004151s: None
2022-05-15 16:49:19,897 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:49:19,901 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] received
2022-05-15 16:49:20,863 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] succeeded in 0.9598387660007575s: None
2022-05-15 17:04:19,907 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:04:19,909 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] received
2022-05-15 17:04:20,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] succeeded in 1.0509080920019187s: None
2022-05-15 17:19:19,913 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:19:19,915 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] received
2022-05-15 17:19:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] succeeded in 1.072206360004202s: None
2022-05-16 06:31:28,696 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:29,188 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 06:31:29,192 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 06:31:29,198 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:30,211 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 06:31:30,234 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 06:31:30,234 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 06:31:52,646 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 06:32:03,510 - celery.beat - INFO - beat: Starting...
2022-05-16 06:32:03,583 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:32:03,591 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] received
2022-05-16 06:32:04,722 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] succeeded in 1.1300137550001637s: None
2022-05-16 06:47:03,590 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:47:03,594 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] received
2022-05-16 06:47:04,597 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] succeeded in 1.0018781310000122s: None
2022-05-16 07:02:03,594 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:02:03,595 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] received
2022-05-16 07:02:04,390 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] succeeded in 0.7929100269998344s: None
2022-05-16 07:17:03,602 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:17:03,605 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] received
2022-05-16 07:17:04,589 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] succeeded in 0.9824386569998751s: None
2022-05-16 07:32:03,610 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:32:03,613 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] received
2022-05-16 07:32:04,675 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] succeeded in 1.060695518999637s: None
2022-05-16 07:47:03,618 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:47:03,621 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] received
2022-05-16 07:47:04,455 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] succeeded in 0.8333607330005179s: None
2022-05-16 08:02:03,627 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:02:03,629 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] received
2022-05-16 08:02:04,563 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] succeeded in 0.9320107300000018s: None
2022-05-16 08:17:03,630 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:17:03,632 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] received
2022-05-16 08:17:04,611 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] succeeded in 0.9778952010001376s: None
2022-05-16 08:32:03,634 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:32:03,635 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] received
2022-05-16 08:32:04,770 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] succeeded in 1.1333998769987375s: None
2022-05-16 08:39:40,192 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:40,697 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 08:39:40,700 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 08:39:40,705 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:41,716 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 08:39:41,735 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 08:39:41,735 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 08:39:54,573 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 08:39:59,197 - celery.beat - INFO - beat: Starting...
2022-05-16 08:47:03,643 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:47:03,660 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] received
2022-05-16 08:47:04,618 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] succeeded in 0.9568373130005057s: None
2022-05-16 09:02:03,647 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:02:03,650 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] received
2022-05-16 09:02:04,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] succeeded in 1.0120177360004163s: None
2022-05-16 09:17:03,656 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:17:03,658 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] received
2022-05-16 09:17:04,576 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] succeeded in 0.916462129998763s: None
2022-05-16 11:18:07,814 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:08,322 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 11:18:08,326 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 11:18:08,331 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:09,342 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 11:18:09,365 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 11:18:09,365 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 11:18:27,255 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 11:18:33,866 - celery.beat - INFO - beat: Starting...
2022-05-16 11:18:33,937 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:18:33,943 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] received
2022-05-16 11:18:34,988 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] succeeded in 1.043751881999924s: None
2022-05-16 11:33:33,944 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:33:33,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] received
2022-05-16 11:33:34,928 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] succeeded in 0.9800666160008404s: None
2022-05-16 11:48:33,952 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:48:33,955 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] received
2022-05-16 11:48:34,967 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] succeeded in 1.0106207190001442s: None
2022-05-16 12:03:33,961 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:03:33,963 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] received
2022-05-16 12:03:34,914 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] succeeded in 0.9488894599999185s: None
2022-05-16 12:18:33,969 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:18:33,972 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] received
2022-05-16 12:18:35,003 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] succeeded in 1.0293517479985894s: None
2022-05-16 12:33:33,978 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:33:33,980 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] received
2022-05-16 12:33:35,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] succeeded in 1.0450792589981575s: None
2022-05-16 12:48:33,985 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:48:33,987 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] received
2022-05-16 12:48:34,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] succeeded in 0.8715320560004329s: None
2022-05-16 13:03:33,987 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:03:33,990 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] received
2022-05-16 13:03:35,244 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] succeeded in 1.2528620049997699s: None
2022-05-16 13:18:33,996 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:18:33,999 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] received
2022-05-16 13:18:35,009 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] succeeded in 1.0087815840015537s: None
2022-05-16 13:33:34,002 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:33:34,005 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] received
2022-05-16 13:33:35,025 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] succeeded in 1.0186987089982722s: None
2022-05-16 13:48:34,010 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:48:34,012 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] received
2022-05-16 13:48:35,014 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] succeeded in 0.9997603140000138s: None
2022-05-16 14:03:34,012 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:03:34,015 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] received
2022-05-16 14:03:34,956 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] succeeded in 0.9401612419969751s: None
2022-05-16 14:18:34,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:18:34,018 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] received
2022-05-16 14:18:35,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] succeeded in 1.127597689999675s: None
2022-05-16 14:33:34,025 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:33:34,028 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] received
2022-05-16 14:33:35,054 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] succeeded in 1.0247761360005825s: None
2022-05-16 14:48:34,034 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:48:34,037 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] received
2022-05-16 14:48:35,024 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] succeeded in 0.9848959180017118s: None
2022-05-16 15:03:34,044 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:03:34,046 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] received
2022-05-16 15:03:35,119 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] succeeded in 1.0713062119975802s: None
2022-05-16 15:18:34,052 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:18:34,055 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] received
2022-05-16 15:18:35,032 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] succeeded in 0.9751865090001957s: None
2022-05-16 15:33:34,059 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:33:34,061 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] received
2022-05-16 15:33:35,134 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] succeeded in 1.0715108379954472s: None
2022-05-16 15:48:34,066 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:48:34,069 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] received
2022-05-16 15:48:35,038 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] succeeded in 0.9677790190035012s: None
2022-05-16 16:03:34,073 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:03:34,076 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] received
2022-05-16 16:03:35,171 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] succeeded in 1.0940112339958432s: None
2022-05-16 16:18:34,082 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:18:34,084 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] received
2022-05-16 16:18:34,997 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] succeeded in 0.9118851110033575s: None
2022-05-16 16:33:34,090 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:33:34,093 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] received
2022-05-16 16:33:35,199 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] succeeded in 1.1039589670035639s: None
2022-05-16 16:48:34,098 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:48:34,100 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] received
2022-05-16 16:48:35,190 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] succeeded in 1.088534027003334s: None
2022-05-16 17:03:34,106 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 17:03:34,108 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] received
2022-05-16 17:03:35,117 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] succeeded in 1.007733956001175s: None
2022-05-17 06:31:51,531 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 06:31:52,049 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 06:31:52,054 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 06:31:52,060 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 06:31:53,071 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 06:31:53,091 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 06:31:53,091 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 06:32:15,085 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 06:32:21,900 - celery.beat - INFO - beat: Starting...
2022-05-17 06:32:21,975 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 06:32:21,983 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ee309754-fdd9-47ba-9b2a-e4b928175356] received
2022-05-17 06:32:28,455 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ee309754-fdd9-47ba-9b2a-e4b928175356] succeeded in 6.470285474000093s: None
2022-05-17 06:47:21,982 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 06:47:21,984 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1d28fc00-5322-4e65-b4db-a687cbda811d] received
2022-05-17 06:47:23,077 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1d28fc00-5322-4e65-b4db-a687cbda811d] succeeded in 1.0906010009998681s: None
2022-05-17 07:02:21,991 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:02:21,993 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6a16bd68-44e0-4371-9f16-cf9d43bccda4] received
2022-05-17 07:02:23,285 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6a16bd68-44e0-4371-9f16-cf9d43bccda4] succeeded in 1.2907497980004337s: None
2022-05-17 07:17:22,000 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:17:22,002 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c453db08-4550-434d-a6e5-222d93f49b96] received
2022-05-17 07:17:23,290 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c453db08-4550-434d-a6e5-222d93f49b96] succeeded in 1.2859622500000114s: None
2022-05-17 07:32:22,008 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:32:22,011 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[59360a51-1dfe-4cfa-9b49-cf4fcf533073] received
2022-05-17 07:32:24,104 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[59360a51-1dfe-4cfa-9b49-cf4fcf533073] succeeded in 2.0916169669999363s: None
2022-05-17 07:47:22,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 07:47:22,019 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c62915fd-335b-4a64-9207-50be75b3dbf9] received
2022-05-17 07:47:24,196 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c62915fd-335b-4a64-9207-50be75b3dbf9] succeeded in 2.1744268399997964s: None
2022-05-17 08:02:22,021 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:02:22,022 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1eb05810-18b0-402c-a624-b610b4df4667] received
2022-05-17 08:02:23,564 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1eb05810-18b0-402c-a624-b610b4df4667] succeeded in 1.53949540099984s: None
2022-05-17 08:17:22,030 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:17:22,032 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b7e2a810-f9e1-4774-b549-18f07ab2394e] received
2022-05-17 08:17:24,241 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b7e2a810-f9e1-4774-b549-18f07ab2394e] succeeded in 2.2071988010002315s: None
2022-05-17 08:32:22,038 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:32:22,041 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e74b27f-e940-40bc-85d6-79eee0918823] received
2022-05-17 08:32:23,960 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e74b27f-e940-40bc-85d6-79eee0918823] succeeded in 1.9180154369996671s: None
2022-05-17 08:47:22,045 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 08:47:22,047 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[23b4be20-d895-4278-99d3-082ee6a86cdd] received
2022-05-17 08:47:23,596 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[23b4be20-d895-4278-99d3-082ee6a86cdd] succeeded in 1.5471598750009434s: None
2022-05-17 09:02:22,052 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:02:22,055 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0dfa6203-2b76-4a61-91e7-23d7746b6438] received
2022-05-17 09:02:27,965 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0dfa6203-2b76-4a61-91e7-23d7746b6438] succeeded in 5.908419228000639s: None
2022-05-17 09:17:22,055 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:17:22,057 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd032df5-5811-4802-9ea8-09e403186405] received
2022-05-17 09:17:24,530 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd032df5-5811-4802-9ea8-09e403186405] succeeded in 2.471370798000862s: None
2022-05-17 09:32:22,063 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:32:22,066 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4be6906d-80ec-4778-b470-7740959ce503] received
2022-05-17 09:32:23,141 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4be6906d-80ec-4778-b470-7740959ce503] succeeded in 1.0727636400006304s: None
2022-05-17 09:47:22,071 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 09:47:22,073 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd118ab7-778f-44c2-8b1e-2e8ca1a80ccf] received
2022-05-17 09:47:24,029 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd118ab7-778f-44c2-8b1e-2e8ca1a80ccf] succeeded in 1.9535806880012387s: None
2022-05-17 10:02:22,075 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:02:22,078 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9a259204-dcc7-482f-a827-50a7bfe6aad4] received
2022-05-17 10:02:23,121 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9a259204-dcc7-482f-a827-50a7bfe6aad4] succeeded in 1.041601491999245s: None
2022-05-17 10:17:22,083 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:17:22,086 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e2b74820-ee46-4d77-9c69-e1c052b5b963] received
2022-05-17 10:17:23,170 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e2b74820-ee46-4d77-9c69-e1c052b5b963] succeeded in 1.0824599210009183s: None
2022-05-17 10:32:22,091 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:32:22,094 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c4e02c56-1951-4661-b526-4e1f917aeda8] received
2022-05-17 10:32:23,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c4e02c56-1951-4661-b526-4e1f917aeda8] succeeded in 1.0520202419993439s: None
2022-05-17 10:47:22,099 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 10:47:22,101 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0d2edca-c976-4cde-8a00-33a25edb6b74] received
2022-05-17 10:47:23,212 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0d2edca-c976-4cde-8a00-33a25edb6b74] succeeded in 1.109383330000128s: None
2022-05-17 10:57:34,818 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 10:57:35,334 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 10:57:35,339 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 10:57:35,345 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 10:57:36,355 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 10:57:36,368 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 10:57:36,368 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 10:57:49,457 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 10:57:53,044 - celery.beat - INFO - beat: Starting...
2022-05-17 11:02:22,113 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:02:22,129 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c25ae071-4352-4262-aaf0-686a7320a103] received
2022-05-17 11:02:23,162 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c25ae071-4352-4262-aaf0-686a7320a103] succeeded in 1.0313276240012783s: None
2022-05-17 11:17:22,115 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:17:22,118 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b7684cdb-cea8-4e68-be6f-3a7985200f97] received
2022-05-17 11:17:23,095 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b7684cdb-cea8-4e68-be6f-3a7985200f97] succeeded in 0.9756028700030583s: None
2022-05-17 11:32:22,124 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:32:22,126 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b9987825-e325-49cd-b5aa-25af8fc75cdf] received
2022-05-17 11:32:23,228 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b9987825-e325-49cd-b5aa-25af8fc75cdf] succeeded in 1.1006480010000814s: None
2022-05-17 11:47:22,132 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 11:47:22,134 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4af424b8-f822-436f-85f9-31027feedca6] received
2022-05-17 11:47:23,075 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4af424b8-f822-436f-85f9-31027feedca6] succeeded in 0.9392859369982034s: None
2022-05-17 12:02:22,139 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:02:22,141 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2e9ee09f-1b90-425c-b980-d6ba0eab16f8] received
2022-05-17 12:02:23,127 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2e9ee09f-1b90-425c-b980-d6ba0eab16f8] succeeded in 0.9845981060025224s: None
2022-05-17 12:17:22,142 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:17:22,145 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eb201fa7-bc1c-4630-a548-186dee7457bc] received
2022-05-17 12:17:23,218 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eb201fa7-bc1c-4630-a548-186dee7457bc] succeeded in 1.0710584150001523s: None
2022-05-17 12:32:22,149 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:32:22,150 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b02b148c-d18f-401a-8c28-17cd6d8b9e75] received
2022-05-17 12:32:23,502 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b02b148c-d18f-401a-8c28-17cd6d8b9e75] succeeded in 1.3503611169981014s: None
2022-05-17 12:47:22,157 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 12:47:22,159 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7de17c85-6ac3-41a4-a731-43e82c9243ba] received
2022-05-17 12:47:23,472 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7de17c85-6ac3-41a4-a731-43e82c9243ba] succeeded in 1.3111561890000303s: None
2022-05-17 13:02:22,166 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:02:22,169 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5439f77c-a0b1-4bbf-a638-3951a1853c13] received
2022-05-17 13:02:23,210 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5439f77c-a0b1-4bbf-a638-3951a1853c13] succeeded in 1.039562317000673s: None
2022-05-17 13:17:22,174 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:17:22,177 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[635bfed8-ace1-4fb5-b56e-2c92735acabc] received
2022-05-17 13:17:23,388 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[635bfed8-ace1-4fb5-b56e-2c92735acabc] succeeded in 1.2091301740001654s: None
2022-05-17 13:32:22,180 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:32:22,183 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[92269ec5-d438-4a25-b10d-52f020d85caa] received
2022-05-17 13:32:23,535 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[92269ec5-d438-4a25-b10d-52f020d85caa] succeeded in 1.351578262001567s: None
2022-05-17 13:47:22,189 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 13:47:22,192 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[69931ba6-f111-45e7-80f1-dcbd68a31260] received
2022-05-17 13:47:24,060 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[69931ba6-f111-45e7-80f1-dcbd68a31260] succeeded in 1.8669047830007912s: None
2022-05-17 16:35:23,258 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 16:35:23,805 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 16:35:23,807 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 16:35:23,812 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 16:35:24,821 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 16:35:24,836 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 16:35:24,836 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 16:35:38,768 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 16:35:44,538 - celery.beat - INFO - beat: Starting...
2022-05-17 16:35:44,610 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 16:35:44,617 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9da69afd-a69d-4763-acfc-5e28f97f305e] received
2022-05-17 16:35:50,774 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9da69afd-a69d-4763-acfc-5e28f97f305e] succeeded in 6.15609538499848s: None
2022-05-17 16:50:44,616 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 16:50:44,619 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[66faba79-a634-4ead-93fd-9d4f1608e69c] received
2022-05-17 16:50:45,648 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[66faba79-a634-4ead-93fd-9d4f1608e69c] succeeded in 1.0282381200013333s: None
2022-05-17 17:04:51,972 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 17:04:52,496 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 17:04:52,499 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 17:04:52,505 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 17:04:53,512 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 17:04:53,523 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 17:04:53,523 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 17:04:58,806 - celery.beat - INFO - beat: Starting...
2022-05-17 17:05:00,320 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 17:05:44,627 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:05:44,642 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d0904bca-f1ab-4f00-ad58-b77536b7e977] received
2022-05-17 17:05:45,686 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d0904bca-f1ab-4f00-ad58-b77536b7e977] succeeded in 1.0418075699999463s: None
2022-05-17 17:20:44,629 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:20:44,634 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3ad4ba18-e378-4c97-bf0b-203548b6060b] received
2022-05-17 17:20:45,801 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3ad4ba18-e378-4c97-bf0b-203548b6060b] succeeded in 1.1655622859980213s: None
2022-05-17 17:35:44,631 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:35:44,633 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4bb93d39-611b-4859-b0bd-8a67d6178941] received
2022-05-17 17:35:45,485 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4bb93d39-611b-4859-b0bd-8a67d6178941] succeeded in 0.8505766739981482s: None
2022-05-17 17:50:44,635 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 17:50:44,637 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a524bd2-c183-43ee-af0f-d1d638c5c598] received
2022-05-17 17:50:45,662 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5a524bd2-c183-43ee-af0f-d1d638c5c598] succeeded in 1.0229675939990557s: None
2022-05-17 18:05:51,720 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 18:05:52,286 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 18:05:52,289 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 18:05:52,294 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 18:05:53,307 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 18:05:53,322 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 18:05:53,322 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 18:05:58,995 - celery.beat - INFO - beat: Starting...
2022-05-17 18:05:59,062 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 18:05:59,070 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b4f56fd9-17f5-44d2-8412-47fff0573634] received
2022-05-17 18:05:59,885 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b4f56fd9-17f5-44d2-8412-47fff0573634] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (107, null, f, 19, 2317).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (107, null, f, 19, 2317).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (107, null, f, 19, 2317).

2022-05-17 18:06:00,466 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 18:20:59,069 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 18:20:59,071 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a49ebf63-2040-4db2-a514-3b416970ad41] received
2022-05-17 18:20:59,829 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a49ebf63-2040-4db2-a514-3b416970ad41] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (108, null, f, 19, 2318).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (108, null, f, 19, 2318).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (108, null, f, 19, 2318).

2022-05-17 20:19:32,232 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:19:32,750 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:19:32,754 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:19:32,760 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:19:33,771 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:19:33,786 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:19:33,787 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:19:49,451 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:19:53,280 - celery.beat - INFO - beat: Starting...
2022-05-17 20:19:53,347 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:19:53,356 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae0573cc-b590-4fc4-b5a3-9548a9d21da6] received
2022-05-17 20:19:54,838 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[ae0573cc-b590-4fc4-b5a3-9548a9d21da6] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (109, null, f, 20, 2320).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (109, null, f, 20, 2320).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (109, null, f, 20, 2320).

2022-05-17 20:35:58,009 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:35:58,521 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:35:58,525 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:35:58,532 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:35:59,543 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:35:59,558 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:35:59,558 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:36:07,311 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:36:12,043 - celery.beat - INFO - beat: Starting...
2022-05-17 20:36:12,109 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:36:12,116 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8733b9e6-4e17-47e3-aef2-080f3ce6a40c] received
2022-05-17 20:36:12,897 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8733b9e6-4e17-47e3-aef2-080f3ce6a40c] raised unexpected: IntegrityError('null value in column "date" of relation "home_notificationmessage" violates not-null constraint\nDETAIL:  Failing row contains (110, null, f, 20, 2325).\n')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
psycopg2.errors.NotNullViolation: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (110, null, f, 20, 2325).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 60, in scrape_twitter
    notifications_create(source, article, pub_date)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/home/logic/services.py", line 47, in notifications_create
    NotificationMessage.objects.create(notification=source_notification, article=article)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1416, in execute_sql
    cursor.execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 98, in execute
    return super().execute(sql, params)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 66, in execute
    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 75, in _execute_with_wrappers
    return executor(sql, params, many, context)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 79, in _execute
    with self.db.wrap_database_errors:
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/utils.py", line 90, in __exit__
    raise dj_exc_value.with_traceback(traceback) from exc_value
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/backends/utils.py", line 84, in _execute
    return self.cursor.execute(sql, params)
django.db.utils.IntegrityError: null value in column "date" of relation "home_notificationmessage" violates not-null constraint
DETAIL:  Failing row contains (110, null, f, 20, 2325).

2022-05-17 20:42:58,420 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:42:58,938 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-17 20:42:58,944 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-17 20:42:58,949 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-17 20:42:59,959 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-17 20:42:59,972 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-17 20:42:59,972 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-17 20:43:05,021 - celery.beat - INFO - beat: Starting...
2022-05-17 20:43:06,739 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-17 20:51:12,111 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 20:51:12,125 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[461d92b1-ac83-42ab-9f3f-75a3e358f8db] received
2022-05-17 20:51:18,528 - celery.redirected - WARNING - 2022-05-17 18:06:08+00:00
2022-05-17 20:51:18,547 - celery.redirected - WARNING - 2022-05-17 17:53:51+00:00
2022-05-17 20:51:18,611 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[461d92b1-ac83-42ab-9f3f-75a3e358f8db] succeeded in 6.484946562995901s: None
2022-05-17 21:06:12,117 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:06:12,119 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8430c560-68d3-41ca-bd05-5f96e98a0f63] received
2022-05-17 21:06:13,209 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8430c560-68d3-41ca-bd05-5f96e98a0f63] succeeded in 1.0880261880010949s: None
2022-05-17 21:21:12,125 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:21:12,127 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[913c67aa-c3be-43dc-a183-5b142874479a] received
2022-05-17 21:21:13,105 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[913c67aa-c3be-43dc-a183-5b142874479a] succeeded in 0.9765800169989234s: None
2022-05-17 21:36:12,132 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:36:12,135 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7b994df5-0428-4318-88ce-d219f0c2933b] received
2022-05-17 21:36:13,533 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7b994df5-0428-4318-88ce-d219f0c2933b] succeeded in 1.397149760996399s: None
2022-05-17 21:51:12,141 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 21:51:12,144 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[96651389-1034-43a7-8675-2fbcd956fa2f] received
2022-05-17 21:51:12,997 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[96651389-1034-43a7-8675-2fbcd956fa2f] succeeded in 0.8520542379992548s: None
2022-05-17 22:06:12,151 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-17 22:06:12,154 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b91f3465-8cc5-462f-96c3-af25f817ced6] received
2022-05-17 22:06:13,156 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b91f3465-8cc5-462f-96c3-af25f817ced6] succeeded in 1.0005229800008237s: None
2022-05-18 06:36:59,856 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-18 06:37:00,366 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-18 06:37:00,370 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-18 06:37:00,374 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-18 06:37:01,384 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-18 06:37:01,406 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-18 06:37:01,406 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-18 06:37:14,291 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-18 06:37:54,654 - celery.beat - INFO - beat: Starting...
2022-05-18 06:37:54,724 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 06:37:54,737 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ebf2ec92-9705-4510-9f68-a0b67848651f] received
2022-05-18 06:37:55,834 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[ebf2ec92-9705-4510-9f68-a0b67848651f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 06:52:54,724 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 06:52:54,726 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[43fb22dc-2b56-4b78-b1e1-3411adb4d5b8] received
2022-05-18 06:52:55,532 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[43fb22dc-2b56-4b78-b1e1-3411adb4d5b8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:07:54,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:07:54,736 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bf7178ad-e6a6-4737-971d-e4e430846397] received
2022-05-18 07:07:55,642 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[bf7178ad-e6a6-4737-971d-e4e430846397] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:22:54,747 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:22:54,749 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f1d7d45c-cf4e-4166-92e5-a215fa855120] received
2022-05-18 07:22:55,566 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f1d7d45c-cf4e-4166-92e5-a215fa855120] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:37:54,750 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:37:54,751 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[53b70408-7574-4545-8da2-6172809b68aa] received
2022-05-18 07:37:55,708 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[53b70408-7574-4545-8da2-6172809b68aa] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 07:52:54,758 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 07:52:54,760 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8f678947-3f00-41b0-bb85-e57a76ffad0c] received
2022-05-18 07:52:55,843 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8f678947-3f00-41b0-bb85-e57a76ffad0c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:07:54,761 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:07:54,763 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a595db1f-732b-4116-83dd-6c07f80b2fda] received
2022-05-18 08:07:56,001 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a595db1f-732b-4116-83dd-6c07f80b2fda] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:22:54,770 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:22:54,772 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9c116b1f-9d9c-4503-8d79-2e5c1ed63239] received
2022-05-18 08:22:56,015 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[9c116b1f-9d9c-4503-8d79-2e5c1ed63239] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:37:54,775 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:37:54,777 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a860e14-cd60-4109-a57a-cdb60a4607b5] received
2022-05-18 08:37:55,711 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5a860e14-cd60-4109-a57a-cdb60a4607b5] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 08:52:54,784 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 08:52:54,786 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e7154151-aada-4aed-9c1c-7bd10c69b9f5] received
2022-05-18 08:52:55,788 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e7154151-aada-4aed-9c1c-7bd10c69b9f5] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:07:54,792 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:07:54,794 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6525337a-28cc-46a0-9d02-de57f384b6c6] received
2022-05-18 09:07:55,943 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[6525337a-28cc-46a0-9d02-de57f384b6c6] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:22:54,801 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:22:54,803 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9e58f911-ce12-4dc7-80a3-4ea7f26b2b79] received
2022-05-18 09:22:55,791 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[9e58f911-ce12-4dc7-80a3-4ea7f26b2b79] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:37:54,809 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:37:54,812 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[505f2b36-158e-4ae9-84f8-a28262180381] received
2022-05-18 09:37:55,782 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[505f2b36-158e-4ae9-84f8-a28262180381] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 09:52:54,811 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 09:52:54,813 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2016f83d-a149-4e0c-b712-ffc1d1e3a454] received
2022-05-18 09:52:55,830 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[2016f83d-a149-4e0c-b712-ffc1d1e3a454] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:07:54,811 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:07:54,813 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c44564b9-371c-46c4-b560-e81c1c5c3158] received
2022-05-18 10:07:55,877 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[c44564b9-371c-46c4-b560-e81c1c5c3158] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:22:54,820 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:22:54,824 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[84e270de-ae8b-408f-96ca-6a76495e3406] received
2022-05-18 10:22:55,856 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[84e270de-ae8b-408f-96ca-6a76495e3406] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:37:54,828 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:37:54,830 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1f0e4011-4948-42fe-8e89-5b2055daadbf] received
2022-05-18 10:37:55,845 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1f0e4011-4948-42fe-8e89-5b2055daadbf] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 10:52:54,839 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 10:52:54,842 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f6082b3a-66cd-4134-9e41-d8bdedeb0804] received
2022-05-18 10:52:56,037 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f6082b3a-66cd-4134-9e41-d8bdedeb0804] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:07:54,848 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:07:54,851 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e767b9f5-e158-485d-8164-4ec5e3acd394] received
2022-05-18 11:07:55,836 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e767b9f5-e158-485d-8164-4ec5e3acd394] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:22:54,856 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:22:54,860 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f580b7f2-9a00-4081-b85d-8f0d1c452305] received
2022-05-18 11:22:55,798 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[f580b7f2-9a00-4081-b85d-8f0d1c452305] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:37:54,866 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:37:54,868 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e6016a48-d562-45ba-abbd-78af2188b73f] received
2022-05-18 11:37:55,830 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[e6016a48-d562-45ba-abbd-78af2188b73f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 11:52:54,868 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 11:52:54,870 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5233d62e-5322-4602-919a-a2132088e91c] received
2022-05-18 11:52:55,772 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5233d62e-5322-4602-919a-a2132088e91c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:07:54,877 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:07:54,878 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[834a769c-5478-4aa0-a8a7-54de02d51660] received
2022-05-18 12:07:55,822 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[834a769c-5478-4aa0-a8a7-54de02d51660] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:22:54,885 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:22:54,887 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[aade3019-9196-43ab-b8e1-24b1d72ccac8] received
2022-05-18 12:22:55,937 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[aade3019-9196-43ab-b8e1-24b1d72ccac8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:37:54,894 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:37:54,896 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1de6f478-e8e4-4c93-b92f-c3eeb3ba1033] received
2022-05-18 12:37:55,868 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1de6f478-e8e4-4c93-b92f-c3eeb3ba1033] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 12:52:54,903 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 12:52:54,907 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6a77ddc2-de3a-4540-a8db-7216dcf0b112] received
2022-05-18 12:52:55,849 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[6a77ddc2-de3a-4540-a8db-7216dcf0b112] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:07:54,912 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:07:54,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[40b3feee-23f7-406a-bf47-ea08ec05aac2] received
2022-05-18 13:07:55,982 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[40b3feee-23f7-406a-bf47-ea08ec05aac2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:22:54,918 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:22:54,921 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1a882d3b-2ade-4024-ae4d-324ce9c7ac1d] received
2022-05-18 13:22:55,926 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1a882d3b-2ade-4024-ae4d-324ce9c7ac1d] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:37:54,922 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:37:54,924 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8989ee98-06c1-4ef5-86a4-17489c721745] received
2022-05-18 13:37:55,913 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8989ee98-06c1-4ef5-86a4-17489c721745] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 13:52:54,930 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 13:52:54,932 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e6cb443-0589-47bd-8325-80d64e80de00] received
2022-05-18 13:52:55,987 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4e6cb443-0589-47bd-8325-80d64e80de00] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-18 14:07:54,937 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-18 14:07:54,939 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8637b635-0862-4828-9e14-b6b975b96feb] received
2022-05-18 14:07:55,818 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8637b635-0862-4828-9e14-b6b975b96feb] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 06:42:04,533 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 06:42:05,041 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 06:42:05,047 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 06:42:05,053 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 06:42:06,065 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 06:42:06,082 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 06:42:06,083 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 06:42:21,804 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 06:42:27,011 - celery.beat - INFO - beat: Starting...
2022-05-19 06:42:27,089 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 06:42:27,100 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4b3e4058-90e3-4c3a-ae5f-6eccb3d99536] received
2022-05-19 06:42:28,885 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4b3e4058-90e3-4c3a-ae5f-6eccb3d99536] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 06:57:27,088 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 06:57:27,089 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a73e3fd1-7b0e-4650-ba28-2135a56f2b6e] received
2022-05-19 06:57:28,043 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a73e3fd1-7b0e-4650-ba28-2135a56f2b6e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:12:27,096 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:12:27,099 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1d257a91-967e-4b7c-8169-48bb1adbc0f4] received
2022-05-19 07:12:28,056 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[1d257a91-967e-4b7c-8169-48bb1adbc0f4] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:27:27,105 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:27:27,108 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b32b0a38-a0a5-47f8-b846-ab1d118dc11a] received
2022-05-19 07:27:28,205 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b32b0a38-a0a5-47f8-b846-ab1d118dc11a] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:42:27,114 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:42:27,116 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cfa03abd-5c7e-4c5e-bc0c-17a1d9cb5ebe] received
2022-05-19 07:42:28,103 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[cfa03abd-5c7e-4c5e-bc0c-17a1d9cb5ebe] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 07:57:27,122 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 07:57:27,125 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[672c8d79-d1d9-4d7c-beeb-afed89bedc9e] received
2022-05-19 07:57:28,147 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[672c8d79-d1d9-4d7c-beeb-afed89bedc9e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:12:27,124 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:12:27,126 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[639f15f3-d2a0-4bff-bcbd-83c70bb15d8f] received
2022-05-19 08:12:28,188 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[639f15f3-d2a0-4bff-bcbd-83c70bb15d8f] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:27:27,133 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:27:27,136 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[286fec76-b505-4d29-8e17-8693752db07e] received
2022-05-19 08:27:29,231 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[286fec76-b505-4d29-8e17-8693752db07e] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:42:27,142 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:42:27,143 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[912dca9a-91b7-4764-be33-5cb0b173b404] received
2022-05-19 08:42:28,083 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[912dca9a-91b7-4764-be33-5cb0b173b404] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 08:57:27,146 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 08:57:27,148 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[99e19d36-2b6d-4827-8ac6-e8d340ecf57c] received
2022-05-19 08:57:28,171 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[99e19d36-2b6d-4827-8ac6-e8d340ecf57c] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:12:27,150 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:12:27,151 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8c20fe78-61f7-451c-8086-cf5e33568cbe] received
2022-05-19 09:12:28,214 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[8c20fe78-61f7-451c-8086-cf5e33568cbe] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.utcnow() - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:27:27,155 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:27:27,157 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4b4f15de-1194-4aa4-924d-e7fa9dbc3ae6] received
2022-05-19 09:27:28,260 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[4b4f15de-1194-4aa4-924d-e7fa9dbc3ae6] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    print(type(datetime.now))
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:42:27,163 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:42:27,166 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5d68c51f-8069-4fe0-b7f7-dd0ec43d3de2] received
2022-05-19 09:42:28,204 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[5d68c51f-8069-4fe0-b7f7-dd0ec43d3de2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 09:57:27,172 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 09:57:27,175 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ffdfba9-24cd-4343-9941-b75b3aee0ab8] received
2022-05-19 09:57:28,348 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[7ffdfba9-24cd-4343-9941-b75b3aee0ab8] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 10:11:50,673 - django_celery_beat.schedulers - INFO - DatabaseScheduler: Schedule changed.
2022-05-19 10:11:50,723 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:11:50,725 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2c1a012-db08-44bd-a1f1-f36042b600b2] received
2022-05-19 10:11:51,755 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[d2c1a012-db08-44bd-a1f1-f36042b600b2] raised unexpected: TypeError("can't subtract offset-naive and offset-aware datetimes")
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 67, in scrape_twitter
    if (datetime.now(timezone.utc) - notification_message.date) > timedelta(hours=24):
TypeError: can't subtract offset-naive and offset-aware datetimes
2022-05-19 10:11:55,755 - django_celery_beat.schedulers - INFO - DatabaseScheduler: Schedule changed.
2022-05-19 10:12:13,565 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:12:14,082 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 10:12:14,086 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 10:12:14,091 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:12:15,102 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 10:12:15,115 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 10:12:15,115 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 10:12:20,408 - celery.beat - INFO - beat: Starting...
2022-05-19 10:12:22,199 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 10:16:50,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:16:50,751 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4989d4d4-ad91-4038-a151-9a83ade28b9b] received
2022-05-19 10:16:51,647 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4989d4d4-ad91-4038-a151-9a83ade28b9b] succeeded in 0.8944745949993376s: None
2022-05-19 10:22:23,375 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:22:23,897 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-19 10:22:23,900 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-19 10:22:23,903 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-19 10:22:24,914 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-19 10:22:24,937 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-19 10:22:24,937 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-19 10:22:32,273 - celery.beat - INFO - beat: Starting...
2022-05-19 10:22:32,342 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:22:32,350 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fd7443ec-fcf0-4707-8e1e-960b38fe3e30] received
2022-05-19 10:22:33,448 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fd7443ec-fcf0-4707-8e1e-960b38fe3e30] succeeded in 1.0972006739993958s: None
2022-05-19 10:22:33,895 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-19 10:27:32,349 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:27:32,352 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[eaf50e5a-8f14-4a40-b3bb-b35f45e0e225] received
2022-05-19 10:27:32,764 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[eaf50e5a-8f14-4a40-b3bb-b35f45e0e225] succeeded in 0.4101717550001922s: None
2022-05-19 10:32:32,357 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:32:32,359 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ec72401b-0e31-485b-bce4-fa4e6bf98f88] received
2022-05-19 10:32:32,822 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ec72401b-0e31-485b-bce4-fa4e6bf98f88] succeeded in 0.4615866989988717s: None
2022-05-19 10:37:32,369 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:37:32,371 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[111ed8db-9496-425c-abf3-10d17286f7bb] received
2022-05-19 10:37:32,722 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[111ed8db-9496-425c-abf3-10d17286f7bb] succeeded in 0.34929178099991987s: None
2022-05-19 10:42:32,375 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:42:32,377 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c3693873-21f6-4ce6-8617-46a98c098bf8] received
2022-05-19 10:42:32,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c3693873-21f6-4ce6-8617-46a98c098bf8] succeeded in 0.48164794399963284s: None
2022-05-19 10:47:32,386 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:47:32,389 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[08824d01-b9c4-483a-a42b-8a4d4df09229] received
2022-05-19 10:47:32,821 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[08824d01-b9c4-483a-a42b-8a4d4df09229] succeeded in 0.43049878500096384s: None
2022-05-19 10:52:32,395 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:52:32,398 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[25309756-9a21-4fea-a9a9-2bebdfb6606d] received
2022-05-19 10:52:32,746 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[25309756-9a21-4fea-a9a9-2bebdfb6606d] succeeded in 0.34643885500190663s: None
2022-05-19 10:57:32,405 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 10:57:32,408 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7a3486f1-b1e1-4f2b-bad6-3e0875601bb0] received
2022-05-19 10:57:32,887 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7a3486f1-b1e1-4f2b-bad6-3e0875601bb0] succeeded in 0.4777644470013911s: None
2022-05-19 11:02:32,412 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:02:32,413 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a926472e-6878-4306-9e93-4567ccc27105] received
2022-05-19 11:02:32,822 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a926472e-6878-4306-9e93-4567ccc27105] succeeded in 0.4081360210002458s: None
2022-05-19 11:07:32,418 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:07:32,421 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0b215689-8d3b-4407-9611-d1c97509a0d1] received
2022-05-19 11:07:32,836 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0b215689-8d3b-4407-9611-d1c97509a0d1] succeeded in 0.413604639001278s: None
2022-05-19 11:12:32,425 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:12:32,427 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[43433073-6836-4a3b-83f7-0ddf49a69cfd] received
2022-05-19 11:12:32,873 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[43433073-6836-4a3b-83f7-0ddf49a69cfd] succeeded in 0.44435993599836365s: None
2022-05-19 11:17:32,432 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:17:32,434 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8b94a4dd-8e85-47c2-a9bd-bf6b52533b6d] received
2022-05-19 11:17:32,831 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8b94a4dd-8e85-47c2-a9bd-bf6b52533b6d] succeeded in 0.39544836999994004s: None
2022-05-19 11:22:32,443 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:22:32,445 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[69f6f0ef-2b20-4f55-8fac-8b2abd61e39a] received
2022-05-19 11:22:32,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[69f6f0ef-2b20-4f55-8fac-8b2abd61e39a] succeeded in 0.4130063450029411s: None
2022-05-19 11:27:32,453 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:27:32,455 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[03f42a0f-af80-4f74-bf1f-015ca353277a] received
2022-05-19 11:27:32,891 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[03f42a0f-af80-4f74-bf1f-015ca353277a] succeeded in 0.4343491699983133s: None
2022-05-19 11:32:32,464 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:32:32,466 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[13019020-587c-4ebe-be9d-2a8af6a993b6] received
2022-05-19 11:32:32,841 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[13019020-587c-4ebe-be9d-2a8af6a993b6] succeeded in 0.37361244200292276s: None
2022-05-19 11:37:32,474 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:37:32,477 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[0bcd53bb-b95e-4d41-81c3-29072510bcfc] received
2022-05-19 11:37:32,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[0bcd53bb-b95e-4d41-81c3-29072510bcfc] succeeded in 0.4829934859990317s: None
2022-05-19 11:42:32,485 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:42:32,490 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[60ec132b-6e69-4188-9a54-ca97c98bc4a6] received
2022-05-19 11:42:32,895 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[60ec132b-6e69-4188-9a54-ca97c98bc4a6] succeeded in 0.40345216100104153s: None
2022-05-19 11:47:32,492 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:47:32,494 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[edbd0428-acc7-45f9-82e2-63500d5c36a8] received
2022-05-19 11:47:32,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[edbd0428-acc7-45f9-82e2-63500d5c36a8] succeeded in 0.46629632999975s: None
2022-05-19 11:52:32,497 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:52:32,499 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6fc26af9-3831-471b-9d06-6f856018a20f] received
2022-05-19 11:52:32,871 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6fc26af9-3831-471b-9d06-6f856018a20f] succeeded in 0.3713765450011124s: None
2022-05-19 11:57:32,502 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 11:57:32,505 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[18c8ac4b-5dd0-4062-84b5-a0e4d585d837] received
2022-05-19 11:57:32,841 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[18c8ac4b-5dd0-4062-84b5-a0e4d585d837] succeeded in 0.3352656589995604s: None
2022-05-19 12:02:32,505 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:02:32,507 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3fe5fe02-94d6-402c-a304-7fd79a49141a] received
2022-05-19 12:02:32,934 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3fe5fe02-94d6-402c-a304-7fd79a49141a] succeeded in 0.4256230070022866s: None
2022-05-19 12:07:32,512 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:07:32,515 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[13c53cf0-5236-4a89-a900-a41196ec653a] received
2022-05-19 12:07:32,852 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[13c53cf0-5236-4a89-a900-a41196ec653a] succeeded in 0.3348443139984738s: None
2022-05-19 12:12:32,523 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:12:32,525 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6c324536-bf0d-4078-9d24-433f0c695779] received
2022-05-19 12:12:32,894 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6c324536-bf0d-4078-9d24-433f0c695779] succeeded in 0.36703133799892385s: None
2022-05-19 12:17:32,534 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:17:32,537 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[89436e5f-b467-4db6-8000-0a1614adac18] received
2022-05-19 12:17:32,915 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[89436e5f-b467-4db6-8000-0a1614adac18] succeeded in 0.3763169949997973s: None
2022-05-19 12:22:32,544 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:22:32,547 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d8d15d31-afee-4a84-8ad0-89313d60fe27] received
2022-05-19 12:22:32,969 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d8d15d31-afee-4a84-8ad0-89313d60fe27] succeeded in 0.4207596800006286s: None
2022-05-19 12:27:32,555 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-19 12:27:32,557 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2d6fe6a4-ba4c-4be9-b933-284b25f0124c] received
2022-05-19 12:27:32,945 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2d6fe6a4-ba4c-4be9-b933-284b25f0124c] succeeded in 0.3872592869993241s: None
