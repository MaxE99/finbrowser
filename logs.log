2022-05-14 10:45:20,900 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 10:45:20,916 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] received
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 2022-05-14 02:53:09+00:00
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,144 - scrapper.tasks - INFO - 20220514-025309
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 2022-05-14 02:52:36+00:00
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,146 - scrapper.tasks - INFO - 20220514-025236
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 2022-05-14 02:52:08+00:00
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,147 - scrapper.tasks - INFO - 20220514-025208
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 2022-05-14 02:48:38+00:00
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,149 - scrapper.tasks - INFO - 20220514-024838
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - 2022-05-14 02:47:50+00:00
2022-05-14 10:45:22,150 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,151 - scrapper.tasks - INFO - 20220514-024750
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 2022-05-13 23:47:38+00:00
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,158 - scrapper.tasks - INFO - 20220513-234738
2022-05-14 10:45:22,161 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 2022-05-13 21:06:15+00:00
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,162 - scrapper.tasks - INFO - 20220513-210615
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 2022-05-13 20:16:48+00:00
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,168 - scrapper.tasks - INFO - 20220513-201648
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,178 - scrapper.tasks - INFO - 2022-05-13 18:01:09+00:00
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,179 - scrapper.tasks - INFO - 20220513-180109
2022-05-14 10:45:22,186 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 2022-05-13 16:31:18+00:00
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,187 - scrapper.tasks - INFO - 20220513-163118
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 2022-05-13 16:20:49+00:00
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 10:45:22,189 - scrapper.tasks - INFO - 20220513-162049
2022-05-14 10:45:22,218 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e825abe1-68fb-4adc-ae29-3126fe8d02b7] succeeded in 1.3010347979979997s: None
2022-05-14 11:00:20,904 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:00:20,907 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] received
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:00:21,727 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:00:21,728 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:00:21,743 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[525c1067-ee88-4541-864f-4034f28f0a93] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:15:20,912 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:15:20,914 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] received
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:15:21,741 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:15:21,742 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:15:21,745 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[b17fd41d-0cd6-4fee-a98d-5b69e1bd0326] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:30:20,919 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 11:30:20,921 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] received
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 2022-05-14 10:55:11+00:00
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 11:30:21,765 - scrapper.tasks - INFO - 20220514-105511
2022-05-14 11:30:21,772 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[a8e31acd-fabd-4240-98b8-fd0ea6372d03] raised unexpected: ValidationError(['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“20220514-105511” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 11:44:25,559 - celery.beat - INFO - beat: Starting...
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Exception ignored in atexit callback
2022-05-14 11:44:29,751 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,751 - celery.redirected - WARNING - <function _exit_function at 0x7f45a0622d40>
2022-05-14 11:44:29,751 - celery.redirected - WARNING - Traceback (most recent call last):
2022-05-14 11:44:29,751 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 334, in _exit_function
2022-05-14 11:44:29,754 - celery.redirected - WARNING -     
2022-05-14 11:44:29,754 - celery.redirected - WARNING - _run_finalizers(0)
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
2022-05-14 11:44:29,755 - celery.redirected - WARNING -     
2022-05-14 11:44:29,755 - celery.redirected - WARNING - finalizer()
2022-05-14 11:44:29,755 - celery.redirected - WARNING -   File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
2022-05-14 11:44:29,756 - celery.redirected - WARNING -     
2022-05-14 11:44:29,756 - celery.redirected - WARNING - res = self._callback(*self._args, **self._kwargs)
2022-05-14 11:44:29,756 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/billiard/pool.py", line 1662, in _terminate_pool
2022-05-14 11:44:29,757 - celery.redirected - WARNING -     
2022-05-14 11:44:29,758 - celery.redirected - WARNING - cls._help_stuff_finish(*help_stuff_finish_args)
2022-05-14 11:44:29,758 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 1341, in _help_stuff_finish
2022-05-14 11:44:29,759 - celery.redirected - WARNING -     
2022-05-14 11:44:29,759 - celery.redirected - WARNING - readable, _, again = _select(inqR, timeout=0.5)
2022-05-14 11:44:29,759 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 165, in _select
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,760 - celery.redirected - WARNING - return poll(readers, writers, err, timeout)
2022-05-14 11:44:29,760 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/concurrency/asynpool.py", line 121, in _select_imp
2022-05-14 11:44:29,760 - celery.redirected - WARNING -     
2022-05-14 11:44:29,761 - celery.redirected - WARNING - events = poller.poll(timeout)
2022-05-14 11:44:29,761 - celery.redirected - WARNING -   File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/apps/worker.py", line 299, in _handle_request
2022-05-14 11:44:29,761 - celery.redirected - WARNING -     
2022-05-14 11:44:29,762 - celery.redirected - WARNING - raise exc(exitcode)
2022-05-14 11:44:29,762 - celery.redirected - WARNING - celery.exceptions
2022-05-14 11:44:29,762 - celery.redirected - WARNING - .
2022-05-14 11:44:29,762 - celery.redirected - WARNING - WorkerTerminate
2022-05-14 11:44:29,762 - celery.redirected - WARNING - : 
2022-05-14 11:44:29,763 - celery.redirected - WARNING - 1
2022-05-14 11:44:31,843 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:32,393 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 11:44:32,396 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 11:44:32,401 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 11:44:33,413 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 11:44:33,438 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 11:44:33,438 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 11:44:35,042 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:15:20,941 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:15:20,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] received
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 2022-05-14 12:15:10+00:00
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - <class 'float'>
2022-05-14 12:15:21,754 - scrapper.tasks - INFO - 1652530510.0
2022-05-14 12:15:21,757 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[3129b05b-30dc-48c0-a557-d72d1e7eb634] raised unexpected: TypeError('expected string or bytes-like object')
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    cache.set('last_id', last_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1367, in to_python
    parsed = parse_datetime(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/utils/dateparse.py", line 107, in parse_datetime
    match = datetime_re.match(value)
TypeError: expected string or bytes-like object
2022-05-14 12:17:57,522 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:58,032 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:17:58,038 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:17:58,044 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:17:59,055 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:17:59,075 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:17:59,075 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:18:16,642 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:18:26,059 - celery.beat - INFO - beat: Starting...
2022-05-14 12:18:26,144 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:18:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] received
2022-05-14 12:18:26,962 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,966 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,975 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,981 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,987 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,993 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:26,999 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,005 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,011 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,020 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,026 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,032 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,038 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,044 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,050 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,052 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,055 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,086 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,094 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,125 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,141 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,168 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,193 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:18:27,251 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[613a0ca2-8ac2-4a53-a9e9-a6503c8222b4] succeeded in 1.0985599829982675s: None
2022-05-14 12:33:26,149 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:33:26,152 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] received
2022-05-14 12:33:27,054 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,067 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,069 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,095 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,097 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,104 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,107 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,134 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,149 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,183 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,208 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,214 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:33:27,269 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9396cc43-b163-46c4-88c8-3b70451351c3] succeeded in 1.1157525369999348s: None
2022-05-14 12:37:40,583 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:41,124 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:37:41,127 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:37:41,131 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:37:42,140 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:37:42,153 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:37:42,153 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:37:55,496 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:38:01,602 - celery.beat - INFO - beat: Starting...
2022-05-14 12:48:26,166 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 12:48:26,181 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] received
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - 2022-05-14 12:48:07+00:00
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'datetime.datetime'>
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]
2022-05-14 12:48:27,068 - scrapper.tasks - INFO - <class 'str'>
2022-05-14 12:48:27,082 - celery.app.trace - ERROR - Task scrapper.tasks.scrape_twitter[2018d1cb-6584-4ae3-a313-d46a0bf44ed0] raised unexpected: ValidationError(['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.'])
Traceback (most recent call last):
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 451, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/app/trace.py", line 734, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/scrapper/tasks.py", line 62, in scrape_twitter
    Article.objects.create(title=title, link=link, pub_date=pub_date, source=source, external_id=external_id)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 453, in create
    obj.save(force_insert=True, using=self.db)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 739, in save
    self.save_base(using=using, force_insert=force_insert,
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 776, in save_base
    updated = self._save_table(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 881, in _save_table
    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/base.py", line 919, in _do_insert
    return manager._insert(
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/manager.py", line 85, in manager_method
    return getattr(self.get_queryset(), name)(*args, **kwargs)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/query.py", line 1270, in _insert
    return query.get_compiler(using=using).execute_sql(returning_fields)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1415, in execute_sql
    for sql, params in self.as_sql():
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1358, in as_sql
    value_rows = [
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1359, in <listcomp>
    [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/sql/compiler.py", line 1300, in prepare_value
    value = field.get_db_prep_save(value, connection=self.connection)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 842, in get_db_prep_save
    return self.get_db_prep_value(value, connection=connection, prepared=False)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1427, in get_db_prep_value
    value = self.get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1406, in get_prep_value
    value = super().get_prep_value(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1266, in get_prep_value
    return self.to_python(value)
  File "/home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/django/db/models/fields/__init__.py", line 1388, in to_python
    raise exceptions.ValidationError(
django.core.exceptions.ValidationError: ['“YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]” value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.']
2022-05-14 12:57:17,676 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:18,242 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-14 12:57:18,245 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-14 12:57:18,249 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-14 12:57:19,259 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-14 12:57:19,269 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-14 12:57:19,269 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-14 12:57:28,245 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-14 12:57:29,701 - celery.beat - INFO - beat: Starting...
2022-05-14 13:03:26,167 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:03:26,184 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] received
2022-05-14 13:03:27,079 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,090 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,114 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,144 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,147 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,150 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,155 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,158 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,180 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,188 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,203 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,225 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,232 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,234 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:03:27,257 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[64b5fa29-ef82-4729-84d3-95aeedfe86c2] succeeded in 1.071642716997303s: None
2022-05-14 13:18:26,172 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-14 13:18:26,175 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] received
2022-05-14 13:18:27,063 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,070 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,072 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,083 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,084 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,085 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,087 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,089 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,096 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,099 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,105 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,117 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,124 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,127 - scrapper.tasks - INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2022-05-14 13:18:27,150 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[beb66de2-5b4a-4bd7-b5d0-585f22b5a482] succeeded in 0.9730412339995382s: None
2022-05-15 06:03:29,186 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:29,708 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-15 06:03:29,712 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-15 06:03:29,726 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-15 06:03:30,739 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-15 06:03:30,759 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-15 06:03:30,760 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-15 06:03:59,089 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-15 06:04:19,529 - celery.beat - INFO - beat: Starting...
2022-05-15 06:04:19,604 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:04:19,611 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] received
2022-05-15 06:04:21,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b0250a80-79f4-48cc-aaf8-cf5a0a1b7b39] succeeded in 1.4147976009999752s: None
2022-05-15 06:19:19,609 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:19:19,612 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] received
2022-05-15 06:19:20,640 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b5aaa484-0757-451e-8eb2-f668e4abfe79] succeeded in 1.026817458000096s: None
2022-05-15 06:34:19,613 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:34:19,615 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] received
2022-05-15 06:34:21,305 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5a4ea00a-7644-411f-a97f-a6c3a3a5d34f] succeeded in 1.6879922109997096s: None
2022-05-15 06:49:19,621 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 06:49:19,624 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] received
2022-05-15 06:49:20,681 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e3455f8-3e65-420b-ba98-43a8ff8c3f4e] succeeded in 1.0558503859997472s: None
2022-05-15 07:04:19,629 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:04:19,631 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] received
2022-05-15 07:04:20,602 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d0ba55dc-b767-4567-bfaf-134e1dbd5345] succeeded in 0.9688271340000938s: None
2022-05-15 07:19:19,636 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:19:19,639 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] received
2022-05-15 07:19:20,583 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3196b0cf-b592-4237-9b36-1eb040b79125] succeeded in 0.9425648280002861s: None
2022-05-15 07:34:19,645 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:34:19,647 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] received
2022-05-15 07:34:20,651 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[333fbfe9-f1d1-4d8c-b87a-7efcd816641f] succeeded in 1.0023042969996823s: None
2022-05-15 07:49:19,650 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 07:49:19,652 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] received
2022-05-15 07:49:25,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c4292f81-25e1-441e-a9de-4f682567ed03] succeeded in 6.01083675100017s: None
2022-05-15 08:04:19,651 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:04:19,653 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] received
2022-05-15 08:04:20,689 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c885b932-1e73-4ce9-9057-401b80b6ccd4] succeeded in 1.0345966639997641s: None
2022-05-15 08:19:19,654 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:19:19,656 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] received
2022-05-15 08:19:20,596 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[85cc670c-e26a-4dfd-ba76-7156ff7182d3] succeeded in 0.9384977319987229s: None
2022-05-15 08:34:19,660 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:34:19,663 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] received
2022-05-15 08:34:20,747 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf3997f9-73aa-4203-9b19-ef7123825aa3] succeeded in 1.0831241819996649s: None
2022-05-15 08:49:19,668 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 08:49:19,671 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] received
2022-05-15 08:49:20,734 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e9be7b78-a570-4083-8479-3ce0004f20e0] succeeded in 1.0619436870001664s: None
2022-05-15 09:04:19,677 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:04:19,679 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] received
2022-05-15 09:04:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e1bb0ddf-b992-4cfc-85c8-86a93b0086a8] succeeded in 1.0476529040006426s: None
2022-05-15 09:19:19,684 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:19:19,686 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] received
2022-05-15 09:19:20,728 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1c1d6a11-cd82-45e8-af65-9c63c2017389] succeeded in 1.0407590319991868s: None
2022-05-15 09:34:19,689 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:34:19,690 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] received
2022-05-15 09:34:20,793 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d76b3e7e-edb4-4411-a52e-5dd8418f6457] succeeded in 1.1009754080005223s: None
2022-05-15 09:49:19,698 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 09:49:19,700 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] received
2022-05-15 09:49:20,824 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7541934d-8c03-47ed-82d9-6bc5676975e6] succeeded in 1.1221691869995993s: None
2022-05-15 10:04:19,707 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:04:19,709 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] received
2022-05-15 10:04:20,620 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e49214f6-1392-45b4-8cd5-3e4481587453] succeeded in 0.9095417999997153s: None
2022-05-15 10:19:19,714 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:19:19,715 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] received
2022-05-15 10:19:20,752 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c0c40403-9068-4a2a-8294-da80f6637764] succeeded in 1.0352385839996714s: None
2022-05-15 10:34:19,718 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:34:19,721 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] received
2022-05-15 10:34:32,181 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f10a860c-0704-4f23-8b68-1a56895db285] succeeded in 12.45846082800199s: None
2022-05-15 10:49:19,725 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 10:49:19,729 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] received
2022-05-15 10:49:20,735 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d87b2307-2f6b-477b-90be-deddca016c67] succeeded in 1.004684849998739s: None
2022-05-15 11:04:19,733 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:04:19,736 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] received
2022-05-15 11:04:20,698 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5bf5b57c-762e-45a2-b9c9-c11646036b53] succeeded in 0.9611234969997895s: None
2022-05-15 11:19:19,741 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:19:19,744 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] received
2022-05-15 11:19:20,751 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a74a1dd4-b257-408f-ae7c-7531c3b0099a] succeeded in 1.005611074000626s: None
2022-05-15 11:34:19,743 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:34:19,745 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] received
2022-05-15 11:34:20,827 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[de3de3fb-e00a-48f4-bbeb-0865e1557fc3] succeeded in 1.079889598000591s: None
2022-05-15 11:49:19,751 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 11:49:19,754 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] received
2022-05-15 11:49:20,799 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[251e9d2a-f4cf-4bc7-bc1c-2d307e9b3e95] succeeded in 1.0442504599996028s: None
2022-05-15 12:04:19,760 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:04:19,762 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] received
2022-05-15 12:04:20,807 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c56ec1ec-e79a-40c1-9732-71a93dea8b97] succeeded in 1.0433865410013823s: None
2022-05-15 12:19:19,768 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:19:19,771 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] received
2022-05-15 12:19:20,846 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a0417b0a-78f4-4a14-b283-80b6afb17a08] succeeded in 1.0730322370000067s: None
2022-05-15 12:34:19,776 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:34:19,779 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] received
2022-05-15 12:34:20,870 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2efa742b-9b11-4281-8214-65dbbb16e4fa] succeeded in 1.0889358870008436s: None
2022-05-15 12:49:19,784 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 12:49:19,786 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] received
2022-05-15 12:49:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6f6dd62c-8481-4c70-a74e-6bc1adaa25b5] succeeded in 1.0519879430030414s: None
2022-05-15 13:04:19,791 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:04:19,793 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] received
2022-05-15 13:04:20,856 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4877a3ff-cd13-47d7-9f67-1f2b51070d2b] succeeded in 1.0612804999982473s: None
2022-05-15 13:19:19,798 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:19:19,800 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] received
2022-05-15 13:19:20,847 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49b2388d-796d-45aa-8b0e-26cf41ceab8d] succeeded in 1.0460207639989676s: None
2022-05-15 13:34:19,804 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:34:19,806 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] received
2022-05-15 13:34:20,905 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5ac6520d-0816-416d-b5d2-517a9f444c71] succeeded in 1.09683028499785s: None
2022-05-15 13:49:19,813 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 13:49:19,816 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] received
2022-05-15 13:49:20,842 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8e552832-3f1b-4f60-9010-9363fce7e4fc] succeeded in 1.0248260299995309s: None
2022-05-15 14:04:19,822 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:04:19,825 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] received
2022-05-15 14:04:20,918 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[75d85dcf-8bd9-440d-82ea-6decc685a5f8] succeeded in 1.092042811000283s: None
2022-05-15 14:19:19,830 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:19:19,832 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] received
2022-05-15 14:19:20,930 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[634a7e49-d36c-43ca-8985-8d0efb983c21] succeeded in 1.096971050999855s: None
2022-05-15 14:34:19,838 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:34:19,841 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] received
2022-05-15 14:34:20,946 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[961ab1a7-790c-464a-9283-685087c052aa] succeeded in 1.1038280469983874s: None
2022-05-15 14:49:19,848 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 14:49:19,852 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] received
2022-05-15 14:49:20,955 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c9ffbfd8-a067-4a63-ad92-b820d2a130d5] succeeded in 1.1017984110003454s: None
2022-05-15 15:04:19,849 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:04:19,850 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] received
2022-05-15 15:04:20,844 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b8b414c5-bdf1-410b-be83-8898491e5f7f] succeeded in 0.9928378679978778s: None
2022-05-15 15:19:19,857 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:19:19,859 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] received
2022-05-15 15:19:21,020 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c67be617-ac29-4199-aa6d-890005bb0aaa] succeeded in 1.1604612469964195s: None
2022-05-15 15:34:19,865 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:34:19,869 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] received
2022-05-15 15:34:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2e2ab8fa-13f0-4487-885e-26b8d746cc25] succeeded in 1.1178659559955122s: None
2022-05-15 15:49:19,873 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 15:49:19,876 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] received
2022-05-15 15:49:21,089 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[aa233262-de23-461c-9ea0-3471b235fece] succeeded in 1.2116717239987338s: None
2022-05-15 16:04:19,881 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:04:19,884 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] received
2022-05-15 16:04:20,840 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae6ec147-8569-47f5-8bdb-cae0d1aa3b7f] succeeded in 0.955031568002596s: None
2022-05-15 16:19:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:19:19,891 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] received
2022-05-15 16:19:20,974 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[10457b87-834b-47b9-ae7d-5a6f8ef73be9] succeeded in 1.0816527050046716s: None
2022-05-15 16:34:19,889 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:34:19,890 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] received
2022-05-15 16:34:20,976 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[6068a705-69e3-4e3d-b8e1-a6ad8874d7bc] succeeded in 1.084029563004151s: None
2022-05-15 16:49:19,897 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 16:49:19,901 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] received
2022-05-15 16:49:20,863 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8109696d-4a24-4325-a3c1-c0998bcac883] succeeded in 0.9598387660007575s: None
2022-05-15 17:04:19,907 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:04:19,909 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] received
2022-05-15 17:04:20,962 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[4e7a3550-0825-4c02-8f14-465900a85a05] succeeded in 1.0509080920019187s: None
2022-05-15 17:19:19,913 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-15 17:19:19,915 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] received
2022-05-15 17:19:20,989 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1885db25-79e3-46ff-ab16-4ec4b3ff30f6] succeeded in 1.072206360004202s: None
2022-05-16 06:31:28,696 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:29,188 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 06:31:29,192 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 06:31:29,198 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 06:31:30,211 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 06:31:30,234 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 06:31:30,234 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 06:31:52,646 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 06:32:03,510 - celery.beat - INFO - beat: Starting...
2022-05-16 06:32:03,583 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:32:03,591 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] received
2022-05-16 06:32:04,722 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f965ef04-c532-4e7f-840b-9c5e44f53675] succeeded in 1.1300137550001637s: None
2022-05-16 06:47:03,590 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 06:47:03,594 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] received
2022-05-16 06:47:04,597 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[716d2a7a-4e33-4c3b-ba40-824f36b1131e] succeeded in 1.0018781310000122s: None
2022-05-16 07:02:03,594 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:02:03,595 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] received
2022-05-16 07:02:04,390 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[849712d9-807c-49cc-ad6a-6ff69750e43e] succeeded in 0.7929100269998344s: None
2022-05-16 07:17:03,602 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:17:03,605 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] received
2022-05-16 07:17:04,589 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[cf57ae71-9d27-4d32-bd0c-a4abd6f1006b] succeeded in 0.9824386569998751s: None
2022-05-16 07:32:03,610 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:32:03,613 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] received
2022-05-16 07:32:04,675 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1fe44d30-7c6d-4b0a-9e73-355b2f9b20e8] succeeded in 1.060695518999637s: None
2022-05-16 07:47:03,618 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 07:47:03,621 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] received
2022-05-16 07:47:04,455 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[f657c221-8f8f-4a8d-930a-ee3e58a9b8dd] succeeded in 0.8333607330005179s: None
2022-05-16 08:02:03,627 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:02:03,629 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] received
2022-05-16 08:02:04,563 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[b331a173-0328-47a4-8de1-7eac720849d5] succeeded in 0.9320107300000018s: None
2022-05-16 08:17:03,630 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:17:03,632 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] received
2022-05-16 08:17:04,611 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[a5225344-429d-49f4-9623-4d6232bcb328] succeeded in 0.9778952010001376s: None
2022-05-16 08:32:03,634 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:32:03,635 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] received
2022-05-16 08:32:04,770 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[8d6bbf2c-47c2-469e-938a-f97623ca7849] succeeded in 1.1333998769987375s: None
2022-05-16 08:39:40,192 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:40,697 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 08:39:40,700 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 08:39:40,705 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 08:39:41,716 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 08:39:41,735 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 08:39:41,735 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 08:39:54,573 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 08:39:59,197 - celery.beat - INFO - beat: Starting...
2022-05-16 08:47:03,643 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 08:47:03,660 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] received
2022-05-16 08:47:04,618 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7ddb02f2-6f61-45dd-bc87-071f6c85202b] succeeded in 0.9568373130005057s: None
2022-05-16 09:02:03,647 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:02:03,650 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] received
2022-05-16 09:02:04,664 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5f8bd270-00cc-436a-b479-2752dc0ee55e] succeeded in 1.0120177360004163s: None
2022-05-16 09:17:03,656 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 09:17:03,658 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] received
2022-05-16 09:17:04,576 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[91ff7b32-234f-4892-931a-bad981d4625f] succeeded in 0.916462129998763s: None
2022-05-16 11:18:07,814 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:08,322 - celery.worker.consumer.connection - INFO - Connected to amqp://guest:**@127.0.0.1:5672//
2022-05-16 11:18:08,326 - celery.worker.consumer.mingle - INFO - mingle: searching for neighbors
2022-05-16 11:18:08,331 - kombu.connection - WARNING - No hostname was supplied. Reverting to default 'localhost'
2022-05-16 11:18:09,342 - celery.worker.consumer.mingle - INFO - mingle: all alone
2022-05-16 11:18:09,365 - py.warnings - WARNING - /home/ebirdmax/Documents/Programmieren/researchbrowserproject-1/venv/lib/python3.10/site-packages/celery/fixups/django.py:203: UserWarning: Using settings.DEBUG leads to a memory
            leak, never use this setting in production environments!
  warnings.warn('''Using settings.DEBUG leads to a memory

2022-05-16 11:18:09,365 - celery.apps.worker - INFO - celery@ebirdmax-HVY-WXX9 ready.
2022-05-16 11:18:27,255 - celery.worker.control - INFO - Events of group {task} enabled by remote.
2022-05-16 11:18:33,866 - celery.beat - INFO - beat: Starting...
2022-05-16 11:18:33,937 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:18:33,943 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] received
2022-05-16 11:18:34,988 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3b357902-8d04-4d16-ad24-0b139428ea53] succeeded in 1.043751881999924s: None
2022-05-16 11:33:33,944 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:33:33,946 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] received
2022-05-16 11:33:34,928 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9f13bfb4-8207-47b7-ad94-ebb11b9780c5] succeeded in 0.9800666160008404s: None
2022-05-16 11:48:33,952 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 11:48:33,955 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] received
2022-05-16 11:48:34,967 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06f858a4-c649-4b4c-99b6-34a8fb8fed50] succeeded in 1.0106207190001442s: None
2022-05-16 12:03:33,961 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:03:33,963 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] received
2022-05-16 12:03:34,914 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[1f006a4e-8f09-4625-b8f7-5828b732c603] succeeded in 0.9488894599999185s: None
2022-05-16 12:18:33,969 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:18:33,972 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] received
2022-05-16 12:18:35,003 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[87f915e0-0870-4d36-aaa9-766f0c156a1b] succeeded in 1.0293517479985894s: None
2022-05-16 12:33:33,978 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:33:33,980 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] received
2022-05-16 12:33:35,027 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[73b63b2f-6384-4de6-ac4c-3f27ec57d5f6] succeeded in 1.0450792589981575s: None
2022-05-16 12:48:33,985 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 12:48:33,987 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] received
2022-05-16 12:48:34,860 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[e0fa0206-b04b-4a24-bb08-5cc5a9d370b6] succeeded in 0.8715320560004329s: None
2022-05-16 13:03:33,987 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:03:33,990 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] received
2022-05-16 13:03:35,244 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[c55e150a-c05c-4f6f-bc89-a1fecd4a0718] succeeded in 1.2528620049997699s: None
2022-05-16 13:18:33,996 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:18:33,999 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] received
2022-05-16 13:18:35,009 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d15e2982-b012-43b9-9d62-08fe589ea043] succeeded in 1.0087815840015537s: None
2022-05-16 13:33:34,002 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:33:34,005 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] received
2022-05-16 13:33:35,025 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[ae1751e3-b193-495c-bc6b-28652707cfeb] succeeded in 1.0186987089982722s: None
2022-05-16 13:48:34,010 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 13:48:34,012 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] received
2022-05-16 13:48:35,014 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[49472137-503d-4d12-a7c2-7f67c9c5ad1c] succeeded in 0.9997603140000138s: None
2022-05-16 14:03:34,012 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:03:34,015 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] received
2022-05-16 14:03:34,956 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[2b2180b7-9db5-4570-91ce-7d30965bede7] succeeded in 0.9401612419969751s: None
2022-05-16 14:18:34,017 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:18:34,018 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] received
2022-05-16 14:18:35,147 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[7054c521-a445-458e-abb5-09623a61b231] succeeded in 1.127597689999675s: None
2022-05-16 14:33:34,025 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:33:34,028 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] received
2022-05-16 14:33:35,054 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3027f0c3-4f82-42da-8eaa-5e5ebaaf8598] succeeded in 1.0247761360005825s: None
2022-05-16 14:48:34,034 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 14:48:34,037 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] received
2022-05-16 14:48:35,024 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[5e8d68bc-7852-4b77-82f7-099eb6c88923] succeeded in 0.9848959180017118s: None
2022-05-16 15:03:34,044 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:03:34,046 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] received
2022-05-16 15:03:35,119 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[06fd8ccb-0b65-4152-bbc7-3a84aa79cb3c] succeeded in 1.0713062119975802s: None
2022-05-16 15:18:34,052 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:18:34,055 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] received
2022-05-16 15:18:35,032 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[fa6a9c31-dea1-4f0e-8e4b-b66684449c26] succeeded in 0.9751865090001957s: None
2022-05-16 15:33:34,059 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:33:34,061 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] received
2022-05-16 15:33:35,134 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[661ca0fe-3e68-4cf8-b467-d8f0b710b056] succeeded in 1.0715108379954472s: None
2022-05-16 15:48:34,066 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 15:48:34,069 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] received
2022-05-16 15:48:35,038 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[50e384d8-63b7-4f9a-9dc5-395d03920b4f] succeeded in 0.9677790190035012s: None
2022-05-16 16:03:34,073 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:03:34,076 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] received
2022-05-16 16:03:35,171 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[bad6e653-27a1-4888-90f9-6af693afd4bf] succeeded in 1.0940112339958432s: None
2022-05-16 16:18:34,082 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:18:34,084 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] received
2022-05-16 16:18:34,997 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[3f0ed5b6-faca-467e-a1a3-7b5faba6093f] succeeded in 0.9118851110033575s: None
2022-05-16 16:33:34,090 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:33:34,093 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] received
2022-05-16 16:33:35,199 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[049b8c21-3e71-497a-90fd-a5ffb1b1da33] succeeded in 1.1039589670035639s: None
2022-05-16 16:48:34,098 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 16:48:34,100 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] received
2022-05-16 16:48:35,190 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[d2c3c743-7ab6-4cd7-895f-00fab27fd006] succeeded in 1.088534027003334s: None
2022-05-16 17:03:34,106 - celery.beat - INFO - Scheduler: Sending due task Twitter Scrapping (scrapper.tasks.scrape_twitter)
2022-05-16 17:03:34,108 - celery.worker.strategy - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] received
2022-05-16 17:03:35,117 - celery.app.trace - INFO - Task scrapper.tasks.scrape_twitter[9a0f721e-e077-4a66-9160-8539b854dcef] succeeded in 1.007733956001175s: None
